ff$SamplingStrategy <- ifelse(ff$SamplingStrategy == "Warning", "Baseline surveillance", ff$SamplingStrategy)
ff$Gender <- "unknown"
ff$Age <- "unknown"
ff$Status <- "unknown"
ff$SpecimenSource <- "unknown"
ff$Outbreak <- ""
ff$lastVaccinated <- ""
ff$Treatment <- ""
# Oxford Nanopore, Illumina MiSeq
ff$SequencingTechnology <- ifelse(ff$PlatePlatform == "Nanopore", "Oxford Nanopore",
ifelse(ff$PlatePlatform == "Illumina", "Illumina MiSeq", "Unknown"))
unknown_tech <- filter(ff, SequencingTechnology == "Unknown")
if (nrow(unknown_tech) != 0){
stop("Check Sequencing Technology options.")
}
ff$AssemblyMethod <- ifelse(ff$PlatePlatform == "Nanopore", "ARTIC Network pipeline",
ifelse(ff$PlatePlatform == "Illumina", "BWA-MEM, iVar", "Unknown"))
unknown_assembly <- filter(ff, AssemblyMethod == "Unknown")
if (nrow(unknown_assembly) != 0){
stop("Check Assembly Method options.")
}
### Coverage
ff$Coverage <- ""
### Originating Lab
ff <- ff %>% mutate(originlab = case_when(received_source == "CDCIVY" ~ "IVY3 Central Lab, Vanderbilt University Medical Center",
T ~ "University of Michigan Clinical Microbiology Laboratory"),
originlabaddress = case_when(received_source == "CDCIVY" ~ "Medical Center North D7240, 1161 21st Ave. S., Nashville, TN, USA",
T ~ "2800 Plymouth Rd, Ann Arbor, MI, USA"))
ff$originlabsampleid <- ""
### submitting Lab
ff$submitlab <- "Lauring Lab, University of Michigan, Department of Microbiology and Immunology"
ff$submitlabaddress <- "1137 Catherine Street, Ann Arbor, MI, USA"
ff$submitlabsampleid <- ""
### Authors
ff$authors <- "Gilbert"
ff$comment <- ""
ff$commenticon <- ""
################################################################################
### write out VirusName + sample_id crosswalk for use in making
# .all.consensus.final.gisaid.fasta
ff_crosswalk <- ff %>% select(sample_id, VirusName)
write.csv(ff_crosswalk, paste0(starting_path, "/SEQUENCING/SARSCOV2/3_ProcessedGenomes/", plate_datef, "_SC2_", runtech, "_Run_", runnum, "/", plate_datef, "_SC2_", runtech, "_Run_", runnum, ".forgisaid.meta.csv"), row.names = FALSE, na = "")
## select variables
ff_writeout <- ff %>% select(Submitter, FASTAfilename, VirusName,Type, Passage,  coll_date, Location,
AdditionalLoc, Host, AdditionalHost, SamplingStrategy, Gender, Age, Status,
SpecimenSource, Outbreak, lastVaccinated, Treatment, SequencingTechnology,
AssemblyMethod, Coverage, originlab, originlabaddress, originlabsampleid,
submitlab, submitlabaddress, submitlabsampleid, authors,
comment, commenticon)
ff_writeout <- ff_writeout %>% distinct()
## gisaid upload file name
today <- current_date_string()
gufn <- paste0(today, "_Lauring_gisaid_upload_metadata_run_", runnum)
## write to excel file (follow format)
wb <- loadWorkbook(paste0(starting_path, "/SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/SequenceOutcomes/gisaid/GISAID_UPLOAD_TEMPLATE2.xlsx"))
# fill in the submissions tab with built data frame
writeData(wb, ff_writeout, sheet = "Submissions", startRow = 3, startCol = 1, colNames = FALSE)
saveWorkbook(wb, paste0(outputLOC, gufn, ".xlsx"), overwrite = TRUE)
################################################################################
#                    GISAID File Upload Format Creation                        #
#                         Last Updated: 06/02/2021                             #
#                 Code Edited By: Julie (Jules) Gilbert                        #
################################################################################
library(tidyverse)
library(openxlsx)
################################################################################
# just need some of these functions
code_path <- "C:/Users/juliegil/Documents/UofM_Work/SequenceCompilationCode/"
source(paste0(code_path, "pipeline_functions.R"))
# set starting path
starting_path <- "C:/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
################################################################################
### fill in some info manually
plate_datef <- "20220111" # plate date in YYYYMMDD format
runtech <- "Nanopore" # nanopore or illumina, will match "PlatePlatform" options
runnum <- "99" # number, will match "PlateNumber" options
# run comparison code file first, to be sure full_compiled_data matches the one
# in the secret folder
source(paste0(code_path, "OutsidePipeline/checking_compiled_files.R"))
# set output path for gisaid upload file
# will need to add appropriate folder name at the end of this path
outputLOC <- paste0(starting_path, "SEQUENCING/SARSCOV2/5_GISAID_Uploads/upload_", plate_datef, "_", tolower(runtech), "_run_", runnum, "/")
################################################################################
# read in full compiled pile
finalfileLOC <- paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary")
final_file <- read.csv(paste0(finalfileLOC, "/full_compiled_data.csv"), colClasses = "character")
# only keep rows with completeness > 90%
ff <- filter(final_file, as.numeric(nextclade_completeness) >= 90)
# select run of choice
ff <- filter(ff, PlatePlatform == runtech & PlateNumber == runnum)
table(ff$received_source, useNA = "always")
#ff <- filter(ff, received_source != "")
################################################################################
# set up alert to duplicate items
if (any(ff$sample_per_subject > 1)){
print("STOP: Examine this set of GISAID submissions.")
stop("There are samples from subject_ids that we've sequenced previously.")
}
ff <- ff %>% mutate(coll_date = case_when(grepl("/", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%m/%d/%Y")),
grepl("-", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%Y-%m-%d")),
T ~ NA_character_))
################################################################################
# enter GISAID username here
ff$Submitter <- "juliegil"
# create FASTA filename string
ff$FASTAfilename <- paste0(ff$PlateName, ".all.consensus.final.gisaid.fasta")
### constants
ff$Type <- "betacoronavirus"
ff$Passage <- "Original"
### create location from state collection location
ff <- separate(data = ff, col = SiteName, sep = "\\_", into = c("Site", "StateAbbrev"))
ff$State <- state.name[match(ff$StateAbbrev,state.abb)]
ff <- ff %>% mutate(Location = case_when(received_source == "CDCIVY" ~ paste0("North America / USA / ", State),
T ~ "North America / USA / Michigan"))
# create virus name
# hCoV-19/USA/MI-UM-10037140915/2020
# hCoV-19/USA/MA-IVY-ZZX9KKEV/2021
ff <- ff %>% mutate(VirusName = case_when(received_source == "CDCIVY" ~ paste0("hCoV-19/USA/", StateAbbrev, "-IVY-", sample_id, "/", substr(coll_date, 1, 4)),
T ~ paste0("hCoV-19/USA/MI-UM-", sample_id, "/", substr(coll_date, 1, 4))))
### constants
ff$AdditionalLoc <- ""
ff$Host <- "Human"
ff$AdditionalHost <- ""
ff <- ff %>% mutate(SamplingStrategy = case_when(sample_per_subject > 1 ~ "Warning",
received_source %in% c("CDCIVY", "MHOME") ~ "",
grepl("PUI", flag) ~ "",
T ~ "Baseline surveillance"))
if(any(ff$SamplingStrategy == "Warning")){
print("Look at this, apply logic if necessary")
## For someone positive > 90 days apart it's tricky. Strictly speaking,
## they would be considered possible reinfection and not longitudinal (and
## therefore surveillance). However, they could be prolonged shedder. One way
## around this would be to look at the lineage in the duplicates, if different,
## then it is reinfection and surveillance for both. Put another way, the
## filter for duplicates would be check dates (>90 days) and check lineage
## (different) in order for it to be considered surveillance.
#ff$SamplingStrategy <- ifelse(ff$SamplingStrategy == "Warning", "Baseline surveillance", ff$SamplingStrategy)
}
#table(ff$SamplingStrategy)
ff$Gender <- "unknown"
ff$Age <- "unknown"
ff$Status <- "unknown"
ff$SpecimenSource <- "unknown"
ff$Outbreak <- ""
ff$lastVaccinated <- ""
ff$Treatment <- ""
# Oxford Nanopore, Illumina MiSeq
ff$SequencingTechnology <- ifelse(ff$PlatePlatform == "Nanopore", "Oxford Nanopore",
ifelse(ff$PlatePlatform == "Illumina", "Illumina MiSeq", "Unknown"))
unknown_tech <- filter(ff, SequencingTechnology == "Unknown")
if (nrow(unknown_tech) != 0){
stop("Check Sequencing Technology options.")
}
### Assembly Method
ff$AssemblyMethod <- ifelse(ff$PlatePlatform == "Nanopore", "ARTIC Network pipeline",
ifelse(ff$PlatePlatform == "Illumina", "BWA-MEM, iVar", "Unknown"))
unknown_assembly <- filter(ff, AssemblyMethod == "Unknown")
if (nrow(unknown_assembly) != 0){
stop("Check Assembly Method options.")
}
### Coverage
ff$Coverage <- ""
### Originating Lab
ff <- ff %>% mutate(originlab = case_when(received_source == "CDCIVY" ~ "IVY3 Central Lab, Vanderbilt University Medical Center",
T ~ "University of Michigan Clinical Microbiology Laboratory"),
originlabaddress = case_when(received_source == "CDCIVY" ~ "Medical Center North D7240, 1161 21st Ave. S., Nashville, TN, USA",
T ~ "2800 Plymouth Rd, Ann Arbor, MI, USA"))
ff$originlabsampleid <- ""
### submitting Lab
ff$submitlab <- "Lauring Lab, University of Michigan, Department of Microbiology and Immunology"
ff$submitlabaddress <- "1137 Catherine Street, Ann Arbor, MI, USA"
ff$submitlabsampleid <- ""
### Authors
ff$authors <- "Gilbert"
ff$comment <- ""
ff$commenticon <- ""
################################################################################
### write out VirusName + sample_id crosswalk for use in making
# .all.consensus.final.gisaid.fasta
ff_crosswalk <- ff %>% select(sample_id, VirusName)
write.csv(ff_crosswalk, paste0(starting_path, "/SEQUENCING/SARSCOV2/3_ProcessedGenomes/", plate_datef, "_SC2_", runtech, "_Run_", runnum, "/", plate_datef, "_SC2_", runtech, "_Run_", runnum, ".forgisaid.meta.csv"), row.names = FALSE, na = "")
## select variables
ff_writeout <- ff %>% select(Submitter, FASTAfilename, VirusName,Type, Passage,  coll_date, Location,
AdditionalLoc, Host, AdditionalHost, SamplingStrategy, Gender, Age, Status,
SpecimenSource, Outbreak, lastVaccinated, Treatment, SequencingTechnology,
AssemblyMethod, Coverage, originlab, originlabaddress, originlabsampleid,
submitlab, submitlabaddress, submitlabsampleid, authors,
comment, commenticon)
ff_writeout <- ff_writeout %>% distinct()
## gisaid upload file name
today <- current_date_string()
gufn <- paste0(today, "_Lauring_gisaid_upload_metadata_run_", runnum)
## write to excel file (follow format)
wb <- loadWorkbook(paste0(starting_path, "/SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/SequenceOutcomes/gisaid/GISAID_UPLOAD_TEMPLATE2.xlsx"))
# fill in the submissions tab with built data frame
writeData(wb, ff_writeout, sheet = "Submissions", startRow = 3, startCol = 1, colNames = FALSE)
saveWorkbook(wb, paste0(outputLOC, gufn, ".xlsx"), overwrite = TRUE)
## only run for updating Slack channel (underworld) with total sample count
shell.exec(paste0(batch_path, "/sample_count_run.bat"))
# Pull of Yesterday's Barcode Scans (patients_collected)
source("S:/SPHCSTP/Results/Daily/QuickUpdate/pull_yest_patients_collected.R")
# Mid-Courier List
source("S:/SPHCSTP/Results/Daily/LynxDxReports/MidCourier/courier_report_piece.R")
case_data <- read.csv("C:/Users/juliegil/Dropbox (University of Michigan)/SPH-COVID Response/Data - MDHHS/22-1-14/Confirmed and Probable Covid19 Cases 2022-01-14.csv")
table(is.na(case_data$City))
table(case_data$City == "")
# 22349 missing City value (1.1%)
ypsilanti_set <- filter(case_data, trimws(tolower(City)) == "ypsilanti" | grepl("ypsi", trimws(tolower(City))))
table(ypsilanti_set$City)
# removed 124 ypsilanti township
ypsilanti_set <- filter(ypsilanti_set, City != "YPSILANTI TOWNSHIP")
lfp <- "C:/Users/juliegil/Dropbox (University of Michigan)/SPH-COVID Response"
################################################################################
# Load in functions
#source("C:/Users/juliegil/Box Sync/COVID Response Modeling/Data - MDHHS/dashboard_scripts/DashboardFunctions/demographic_variable_processing.R")
#source("C:/Users/juliegil/Box Sync/COVID Response Modeling/Data - MDHHS/dashboard_scripts/DashboardFunctions/major_mdhhs_function_v2.R")
source(paste0(lfp, "/Data - MDHHS/dashboard_scripts/DashboardFunctions/demographic_variable_processing.R"))
source(paste0(lfp, "/Data - MDHHS/dashboard_scripts/DashboardFunctions/major_mdhhs_function_v2.R"))
#table(data$Age, data$Age_Units)
#nrow(filter(data, Age == 12 & Age_Units == "M"))
# =========== Reformat Dates ==================
data <- date_reformatting(ypsilanti_set)
### data check: if all the dates used in the next variable creation step
# are missing, stop the code run
if(all(is.na(data$Onset_Date))){
stop("All Onset_Date are missing.")
}
if(all(is.na(data$Referral_Date))){
stop("All Referral_Date are missing.")
}
if(all(is.na(data$CovidTestDate))){
stop("All CovidTestDate are missing.")
}
# create new date variable based on logic from Sarah Rockhill
# see Box\COVID Response Modeling\Data - MDHHS\state_data_pipeline_documentation\Notes_and_Other.docx for more info
data <- date_fill_order(data)
###############
data_y <- data %>% group_by(Date, Case_Status) %>% summarize(count = length(unique(InvestigationID)))
table(case_data$Case_Status)
case_data %>% group_by(Case_Status) %>% summarize(count = length(unique(InvestigationID)))
data_y <- reshape2::dcast(data_y, Date ~ Case_Status, value.var = c("count"))
data_y[is.na(data_y)] <- 0
date_expand <- seq(min(data_y$Date), max(data_y$Date), by = 1)
head(data_expand)
head(date_expand)
Confirmed_zeros <- rep(0, length(date_expand))
Probable_zeros <- rep(0, length(date_expand))
fill_ins <- as.data.frame(date_expand, Confirmed_zeros, Probable_zeros)
View(fill_ins)
head(Confirmed_zeros)
fill_ins <- as.data.frame(c(date_expand, Confirmed_zeros, Probable_zeros))
fill_ins <- data.frame(date_expand, Confirmed_zeros, Probable_zeros)
colnames(fill_ins) <- c("Date", "Confirmed", "Probable")
data_y <- merge(data_y, fill_ins, by = c("Date"), all.x = TRUE, all.y = FALSE)
View(data_y)
fill_ins <- data.frame(date_expand)
colnames(fill_ins) <- c("Date")
data_y <- data %>% group_by(Date, Case_Status) %>% summarize(count = length(unique(InvestigationID)))
data_y <- reshape2::dcast(data_y, Date ~ Case_Status, value.var = c("count"))
data_y[is.na(data_y)] <- 0
data_y <- merge(data_y, fill_ins, by = c("Date"), all.x = TRUE, all.y = FALSE)
data_y[is.na(data_y)]
data_y[is.na(data_y)] <- 0
sum(data_y$Confirmed)
sum(data_y$Probable)
17436 + 2630
write.csv(data_y, "C:/Users/juliegil/Dropbox (University of Michigan)/SPH-COVID Response/Jules/Cases_WWregions_forKevin/ypsilanti_city_cases_20220119.csv", row.names = FALSE, na = "")
library(tidyverse)
library(lubridate)
################################################################################
starting_path <- "C:/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
outputLOC <- paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/CDC_IVY_UPLOADS/")
seq_list <- read.csv(paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/full_compiled_data.csv"), colClasses = "character")
seq_list_o <- read.csv(paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/full_compiled_data.csv"), colClasses = "character")
################################################################################
seq_list <- seq_list %>% select(sample_id, subject_id, coll_date,
flag, received_source, SiteName, SampleBarcode,
PlateDate, PlatePlatform, PlateNumber,
pangolin_lineage, pangolin_probability, pangolin_status,
pangolin_note, nextclade_clade, nextclade_totalMissing,
nextclade_completeness, gisaid_strain, gisaid_epi_isl,
received_date, position,
PlateName, PlatePosition, SampleSourceLocation,
pangoLEARN_version, pangolin_conflict, pango_version,
pangolin_version, pangolin_runDate, PlateToPangolin_days,
nextclade_qcOverallScore, nextclade_qcOverallStatus, nextclade_totalMutations,
nextclade_totalNonACGTNs, nextclade_runDate, PlateToNextclade_days)
seq_list_o <- seq_list_o %>% select(sample_id, subject_id, coll_date,
flag, received_source, SiteName, SampleBarcode,
PlateDate, PlatePlatform, PlateNumber,
pangolin_lineage, pangolin_probability, pangolin_status,
pangolin_note, nextclade_clade, nextclade_totalMissing,
nextclade_completeness, gisaid_strain, gisaid_epi_isl,
received_date, position,
PlateName, PlatePosition, SampleSourceLocation,
pangoLEARN_version, pangolin_conflict, pango_version,
pangolin_version, pangolin_runDate, PlateToPangolin_days,
nextclade_qcOverallScore, nextclade_qcOverallStatus, nextclade_totalMutations,
nextclade_totalNonACGTNs, nextclade_runDate, PlateToNextclade_days)
seq_list <- filter(seq_list, received_source == "CDCIVY")
if (length(unique(seq_list$sample_id)) != nrow(seq_list)){
stop("Duplicate sample IDs - handle accordingly")
}
## remove study withdraws
seq_list <- filter(seq_list, flag != "Withdrawn from study")
################################################################################
### fix date formatting
seq_list <- seq_list %>% mutate(coll_date = case_when(grepl("/", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%m/%d/%Y")),
grepl("-", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%Y-%m-%d")),
T ~ NA_character_))
seq_list_o <- seq_list_o %>% mutate(coll_date = case_when(grepl("/", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%m/%d/%Y")),
grepl("-", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%Y-%m-%d")),
T ~ NA_character_))
################################################################################
# create portion for qPCR matching
qpcr <- seq_list %>% select(sample_id, subject_id, coll_date, PlateName, PlatePosition)
qpcr_full <- filter(seq_list_o, PlateName %in% unique(qpcr$PlateName)) %>% select(sample_id, subject_id, coll_date, PlateName, PlatePosition, received_source, flag)
pmc <- read.csv("C:/Users/juliegil/Documents/UofM_Work/Lauring_Lab/plate_map_cross.csv")
qpcr_full <- merge(qpcr_full, pmc, by.x = c("PlatePosition"), by.y = c("Slot"), all.x = TRUE)
qpcr_full$wellgrid <- paste0(qpcr_full$Letter, qpcr_full$Number)
qpcr_full <- qpcr_full %>% arrange(PlateName, Letter, Number)
write.csv(qpcr_full, "C:/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/SEQUENCING/SARSCOV2/8_QPCR_IVY/IVY_Locations/ivy_mapping.csv", row.names = FALSE, na = "")
# id_count <- seq_list %>% group_by(sample_id) %>% summarize(count = length(subject_id))
# seq_list <- merge(seq_list, id_count, by = c("sample_id"), all.x = TRUE)
#
# dupes <- filter(seq_list, count > 1)
### if we need to manually put in gisaid info
# only keep complete rows?
################################################################################
# 6/18/2021 - no longer need this - will be doing full overwrite upload going forward
# After the first upload, we'll need to keep track of what has already been uploaded
# so we'll read in the full list, then read in the previous upload list, and only keep
# rows that are not in the previous upload list(s) to write out and upload the next time
# ivy_file_list <- list.files(pattern = "*.csv", path = paste0(outputLOC, "ARCHIVE/"))
#
# ivy_redcap <- data.frame()
# for (i in ivy_file_list){
#   one <- read.csv(paste0(outputLOC, "ARCHIVE/", i), colClasses = "character")
#   ivy_redcap <- rbind(ivy_redcap, one)
# }
#
# # select only rows from seqlist that are not in ivy_redcap
# combo <- anti_join(seq_list, ivy_redcap)
#length(unique(combo$sample_id))
#combo$flag <- ifelse(grepl("REDO", combo$SampleSourceLocation), "Re-run sample from batch #1", "")
################################################################################
colnames(seq_list) <- tolower(colnames(seq_list))
# add leading zero to month
if (nchar(month(Sys.Date())) == 1){
m <- paste0("0", month(Sys.Date()))
} else {
m <- month(Sys.Date())
}
# add leading zero to day
if (nchar(day(Sys.Date())) == 1){
d <- paste0("0", day(Sys.Date()))
} else {
d <- day(Sys.Date())
}
today <- paste0(year(Sys.Date()), m, d)
#seq_list <- filter(seq_list, platenumber <= 49)
write.csv(seq_list, paste0(outputLOC, "cdc_ivy_", today, ".csv"), row.names = FALSE, na = "")
View(seq_list)
library(sf)
library(tidyverse)
library(leaflet)
library(tidyverse)
library(htmlwidgets)
library(tidycensus)
library(lubridate)
### wastewater shape files
census_api_key("bdadb17ac3cdebcc23518a2367b622f8bcc24084")
county_geo <- get_acs(state = "MI", geography = "county",
variables = "B19013_001", geometry = TRUE)
county_geo$NAME2 <- gsub(" County, Michigan", "", county_geo$NAME)
county_geo$NAME2 <- gsub("\\.", "", county_geo$NAME2)
# read in a location
location1 <- "C:/Users/juliegil/Documents/ArcGIS/Projects/CreateShapeFiles3/city_of_flint_wpcf_service_area.shp"
# convert it to shape file system (R)
tx <- st_read(location1, stringsAsFactors=FALSE)
tx_ll <- st_transform(tx, "+proj=longlat +ellps=WGS84 +datum=WGS84")
tx_ll <- st_as_sf(tx_ll)
tx_ll <- st_cast(tx_ll, to = c("POLYGON"))
# can use this code to test the shape file view
# theme1.leaf <- leaflet() %>% addPolygons(data = county_geo$geometry,fillColor = "#FFFFFF",
#                                          color = "#000000", # you need to use hex colors
#                                          fillOpacity = 1,
#                                          weight = 1,
#                                          smoothFactor = 0.2) %>%
#                             addPolygons(data = tx_ll$geometry,
#                                           color = "#5F7367", # you need to use hex colors
#                                           fillOpacity = 1,
#                                           weight = 1,
#                                           smoothFactor = 0.2) %>%
#                               addCircles(lng = data_use$long, lat = data_use$lat)
#
# saveWidget(theme1.leaf,"C:/Users/juliegil/Dropbox (University of Michigan)/SPH-COVID Response/Jules/Cases_WWregions_forKevin/test_region.html",selfcontained=T)
### case data
cases <- read.csv("C:/Users/juliegil/Dropbox (University of Michigan)/SPH-COVID Response/Data - MDHHS/22-1-19/Confirmed and Probable Covid19 Cases 2022-01-19.csv")
## select columns to work with, to improve processing time as this file has gotten large
data <- cases %>% select(InvestigationID, Case_Status, State_Prison_Case,
Onset_Date, Diagnosis_Date, Referral_Date, Case_Entry_Date, Case_Disposition,
Patient_Status, Patient_Status_Date, Patient_ID, Age, Age_Units,
Sex_at_Birth, Race, Hispanic_Ethnicity, Arab_Ethnicity,
City, State, Zip, County, Patient_Hospitalized,
Admission_Date, Discharge_Date, Days_Hospitalized, Patient_Died,
Date_of_Death, CovidTest, Health_care_worker_in_the_US,
CovidTestDate, CovidResult, Investigation_Addr_Geo_X, Investigation_Addr_Geo_Y) %>% distinct()
lfp <- "C:/Users/juliegil/Dropbox (University of Michigan)/SPH-COVID Response"
################################################################################
# Load in functions
#source("C:/Users/juliegil/Box Sync/COVID Response Modeling/Data - MDHHS/dashboard_scripts/DashboardFunctions/demographic_variable_processing.R")
#source("C:/Users/juliegil/Box Sync/COVID Response Modeling/Data - MDHHS/dashboard_scripts/DashboardFunctions/major_mdhhs_function_v2.R")
source(paste0(lfp, "/Data - MDHHS/dashboard_scripts/DashboardFunctions/demographic_variable_processing.R"))
source(paste0(lfp, "/Data - MDHHS/dashboard_scripts/DashboardFunctions/major_mdhhs_function_v2.R"))
#table(data$Age, data$Age_Units)
#nrow(filter(data, Age == 12 & Age_Units == "M"))
# =========== Reformat Dates ==================
data <- date_reformatting(data)
### data check: if all the dates used in the next variable creation step
# are missing, stop the code run
if(all(is.na(data$Onset_Date))){
stop("All Onset_Date are missing.")
}
if(all(is.na(data$Referral_Date))){
stop("All Referral_Date are missing.")
}
if(all(is.na(data$CovidTestDate))){
stop("All CovidTestDate are missing.")
}
# create new date variable based on logic from Sarah Rockhill
# see Box\COVID Response Modeling\Data - MDHHS\state_data_pipeline_documentation\Notes_and_Other.docx for more info
data <- date_fill_order(data)
# if all the dates for the next date manipulation are missing, stop the code
if(all(is.na(data$Patient_Status_Date))){
stop("All Patient_Status_Date are missing.")
}
if(all(is.na(data$Date_of_Death))){
stop("All Date_of_Death are missing.")
}
# change "Date_of_Death" to "DateDeath"
data$DateDeath <- data$Date_of_Death
# if DateDeath is missing, fill it with Patient_Status_Date
data$DateDeath[is.na(data$DateDeath)] <- data$Patient_Status_Date[is.na(data$DateDeath)]
# Remove any rows where all the individual's main date values are missing (at this point,
# if all their dates are missing, the "Date" variable will be NA)
data <- data[which(!is.na(data$Date)),]
data <- data %>% mutate(
age_years = case_when(Age_Units %in% c("D") ~ 0,
Age_Units == "M" & Age < 12 ~ 0,
Age_Units == "M" & Age >= 12 & Age < 24 ~ 1,
T ~ as.numeric(Age)),
County = case_when(is.na(County) ~ "Unknown",
T ~ County))
data <- data %>% select(Date, County, InvestigationID, Case_Status, Investigation_Addr_Geo_X, Investigation_Addr_Geo_Y)
# overall information on missing lat/long
table(is.na(data$Investigation_Addr_Geo_X), is.na(data$Investigation_Addr_Geo_Y))
# 33736 were missing lat/long info (2.2%) [1567578]
table(is.na(data$Investigation_Addr_Geo_X), data$Case_Status)
# 12145 (6.5%) missing lat/long for probable cases [187254]
# 21591 (1.6%) missing lat/long for confirmed cases [1380324]
data$nolatlong <- ifelse(is.na(data$Investigation_Addr_Geo_X) | is.na(data$Investigation_Addr_Geo_Y), 1, 0)
#table(is.na(data_school$Investigation_Addr_Geo_X), is.na(data_school$Investigation_Addr_Geo_Y))
table(data$nolatlong)
county <- filter(data, County == "Genesee")
table(county$Case_Status)
data_use <- filter(data, nolatlong == 0 & County == "Genesee") %>% distinct()
# y = latitude
colnames(data_use) <- c("Date", "County", "InvestigationID", "Case_Status",
"long", "lat", "nolatlong")
dsf <- sf::st_as_sf(data_use, coords=c("long","lat"), crs=4326)
#
# pnts <- dsf %>% mutate(
#   intersection = as.integer(st_intersects(geometry, tx_ll))
#   , area = if_else(is.na(intersection), '', "yes")
# )
#poly <- st_polygon(list(tx_ll$geometry))
# Find country of each coordinate:
#int_list <- sf::st_contains(dsf, tx_ll)
sf_join <- sf::st_join(dsf, tx_ll, join = st_intersects)
#kept_points <- st_intersection(poly, dsf)
# out <- do.call(c, lapply(int_list, (function(x) {
#   if (is.null(x) | length(x) == 0) {NA} else { x }
# })))
#
# dsf$row_id <- out
# ### OBJECTID_1 -- no, row id?
#
# dsf <- as.data.frame(dsf)
# tx_ll <- as.data.frame(tx_ll)
#
# tx_ll$row_id <- row.names(tx_ll)
#
# #write.csv(select(tx_ll, row_id, NAME), "C:/Users/juliegil/Dropbox (University of Michigan)/SPH-COVID Response/Jules/Cases_WWregions_forKevin/shape_file_names.csv", row.names = FALSE, na = "")
#
#
# df_cases <- merge(dsf, tx_ll, by.x = c("row_id"), by.y = c("row_id"), all.x = TRUE)
# colnames(df_cases)
table(sf_join$Id, useNA = "always")
sf_join <- as.data.frame(sf_join)
df_out <- filter(sf_join, Id == 0) %>% group_by(Date, Case_Status) %>% summarize(count = length(unique(InvestigationID)))
days <- seq(min(as_date(df_out$Date)), max(as_date(df_out$Date)), by='days')
days_2 <- c(days, days)
conf <- rep("Confirmed", length(days))
prob <- rep("Probable", length(days))
types_2 <- c(conf, prob)
day_df <- data.frame(Date = days_2, Case_Status = types_2)
df_out_test <- merge(df_out, day_df, by = c("Date", "Case_Status"), all = TRUE)
df_out_test[is.na(df_out_test)] <- 0
# sum(df_out_test$count)
# sum(df_out$count)
write.csv(df_out_test, "C:/Users/juliegil/Dropbox (University of Michigan)/SPH-COVID Response/Jules/Cases_WWregions_forKevin/flint_out_20220119.csv", row.names = FALSE, na = "")

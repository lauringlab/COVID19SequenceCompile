mani_plate <- rbind(mani_plate, mani_plate2)
# then, read in pangolin, gisaid, and next clade files
nextclade <- read.csv(paste0(nc_fp, "/sample_full_nextclade_list.csv"), colClasses = "character")
gisaid <- read.csv(paste0(gisaid_fp, "/gisaid_epiflu_isolates.csv"), colClasses = "character")
gisaid <- gisaid %>% select(Isolate_Id, HA.Segment_Id, Isolate_Name)
gisaid <- separate(data = gisaid, col = Isolate_Name, remove = FALSE, sep = "/", into = c("type", "place", "id", "year"))
gisaid$id <- gsub("UOM", "", gisaid$id)
gisaid <- gisaid %>% select(id, Isolate_Id, HA.Segment_Id, Isolate_Name)
colnames(gisaid) <- c("sample_id", "Isolate_Id", "HA.Segment_Id", "Isolate_Name")
mani_plate_g <- merge(mani_plate, gisaid, by.x = c("sample_id"), by.y = c("sample_id"), all.x = TRUE)
mppnc <- merge(mani_plate_g, nextclade, by.x = c("sample_id"), by.y = c("SampleID"), all.x = TRUE)
### add column for time in days from plate to nextclade
mppnc$PlateToNextclade_days <- difftime(mppnc$nextclade_HA_runDate, mppnc$PlateDate, units = "days")
View(mppnc)
a <- mppnc %>% group_by(nextclade_HA_runDate) %>% summarize(count = length(unique(sample_id)))
View(a)
b <- mppnc %>% group_by(PlateDate) %>% summarize(count = length(unique(sample_id)))
View(b)
filter(mppnc, PlateDate == "2022-+A-30")
source(paste0(influenza_path, "influenza_manifestcode.R"))
source(paste0(influenza_path, "influenza_platemapcode.R"))
source(paste0(influenza_path, "influenza_nextcladecode.R"))
### will need a piece to incorporate gisaid returns
### need to compile everything
source(paste0(influenza_path, "influenza_compilecomponentscode.R"))
library(tidyverse)
library(lubridate)
################################################################################
# set paths
starting_path <- "/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
## set run folder accordingly
outputLOC <- paste0(starting_path, "SEQUENCING/INFLUENZA_A/3_ProcessedGenomes/20220407_IAV_Nanopore_Run_16/")
# read in compiled dataset
seq_list <- read.csv(paste0(starting_path, "SEQUENCING/INFLUENZA_A/4_SequenceSampleMetadata/FinalSummary/full_compiled_data.csv"), colClasses = "character")
################################################################################
# filter to plate run
seq_list2 <- filter(seq_list, PlateNumber == "16" & PlateDate == "2022-04-07")
# write out that file as the .meta.csv file - change name as appropriate
write.csv(seq_list2, paste0(outputLOC, "20220407_IAV_Nanopore_Run_16.meta.csv"), row.names = FALSE, na = "")
source(paste0(influenza_path, "influenza_manifestcode.R"))
source(paste0(influenza_path, "influenza_platemapcode.R"))
source(paste0(influenza_path, "influenza_nextcladecode.R"))
### will need a piece to incorporate gisaid returns
### need to compile everything
source(paste0(influenza_path, "influenza_compilecomponentscode.R"))
# load libraries
library(tidyverse)
library(lubridate)
################################################################################
# set paths
starting_path <- "/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
## set run folder accordingly
outputLOC <- paste0(starting_path, "SEQUENCING/INFLUENZA_A/3_ProcessedGenomes/20220407_IAV_Nanopore_Run_16/")
# read in compiled dataset
seq_list <- read.csv(paste0(starting_path, "SEQUENCING/INFLUENZA_A/4_SequenceSampleMetadata/FinalSummary/full_compiled_data.csv"), colClasses = "character")
################################################################################
# filter to plate run
seq_list2 <- filter(seq_list, PlateNumber == "16" & PlateDate == "2022-04-07")
#puis <- filter(seq_list, grepl("pui", tolower(flag)) | grepl("pui", tolower(SampleSourceLocation)))
# for use for identifying missing manifests
# out <- filter(seq_list2, subject_id == "")
# write.csv(out, "C:/Users/juliegil/Dropbox (University of Michigan)/Personal_DropBox/2021/MissingManifests/run40_20210823.csv", row.names = FALSE, na = "")
# write out that file as the .meta.csv file - change name as appropriate
write.csv(seq_list2, paste0(outputLOC, "20220407_IAV_Nanopore_Run_16.meta.csv"), row.names = FALSE, na = "")
library(tidyverse)
library(lubridate)
################################################################################
# set paths
starting_path <- "/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
## set run folder accordingly
outputLOC <- paste0(starting_path, "SEQUENCING/INFLUENZA_A/3_ProcessedGenomes/20220408_IAV_Nanopore_Run_16/")
# read in compiled dataset
seq_list <- read.csv(paste0(starting_path, "SEQUENCING/INFLUENZA_A/4_SequenceSampleMetadata/FinalSummary/full_compiled_data.csv"), colClasses = "character")
################################################################################
# filter to plate run
seq_list2 <- filter(seq_list, PlateNumber == "16" & PlateDate == "2022-04-08")
#puis <- filter(seq_list, grepl("pui", tolower(flag)) | grepl("pui", tolower(SampleSourceLocation)))
# for use for identifying missing manifests
# out <- filter(seq_list2, subject_id == "")
# write.csv(out, "C:/Users/juliegil/Dropbox (University of Michigan)/Personal_DropBox/2021/MissingManifests/run40_20210823.csv", row.names = FALSE, na = "")
# write out that file as the .meta.csv file - change name as appropriate
write.csv(seq_list2, paste0(outputLOC, "20220408_IAV_Nanopore_Run_16.meta.csv"), row.names = FALSE, na = "")
source(paste0(influenza_path, "influenza_manifestcode.R"))
source(paste0(influenza_path, "influenza_platemapcode.R"))
source(paste0(influenza_path, "influenza_nextcladecode.R"))
### will need a piece to incorporate gisaid returns
### need to compile everything
source(paste0(influenza_path, "influenza_compilecomponentscode.R"))
library(tidyverse)
library(openxlsx)
library(reshape2)
################################################################################
# just need some of these functions
code_path <- "/Users/juliegil/Documents/git_synced_code/SequenceCompilationCode/COVID19SequenceCompile/"
source(paste0(code_path, "pipeline_functions.R"))
# set starting path
starting_path <- "/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
################################################################################
### fill in some info manually
plate_datef <- "20220408" # plate date in YYYYMMDD format
runtech <- "Nanopore" # nanopore or illumina, will match "PlatePlatform" options
runnum <- "16" # number, will match "PlateNumber" options
seq_list_path <- paste0("/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/SEQUENCING/INFLUENZA_A/3_ProcessedGenomes/", plate_datef, "_IAV_Nanopore_Run_", runnum, "/Segment_sequences/")
code_path2 <- "/Users/juliegil/Documents/git_synced_code/SequenceCompilationCode/COVID19SequenceCompile/InfluenzaACode/"
source(paste0(code_path2, "OutsidePipeline/comparing_full_secret_influenza.R"))
# set output path for gisaid upload file
# will need to add appropriate folder name at the end of this path
outputLOC <- paste0(starting_path, "SEQUENCING/INFLUENZA_A/5_GISAID_Uploads/upload_", plate_datef, "_iav_", tolower(runtech), "_run_", runnum, "/")
################################################################################
# read in full compiled pile
finalfileLOC <- paste0(starting_path, "SEQUENCING/INFLUENZA_A/4_SequenceSampleMetadata/FinalSummary")
final_file <- read.csv(paste0(finalfileLOC, "/full_compiled_data.csv"), colClasses = "character")
# remove any with missing collection date
final_file <- filter(final_file, !grepl("Replaced with Today Date", flag) & received_source != "WW")
# only keep rows with completeness > 90%
ff <- filter(final_file, as.numeric(nextclade_HA_completeness) >= 90)
# select run of choice
ff <- filter(ff, PlatePlatform == runtech & PlateNumber == runnum)
if (any(ff$sample_per_subject > 1)){
print("STOP: Examine this set of GISAID submissions.")
stop("There are samples from subject_ids that we've sequenced previously.")
}
################################################################################
### fix date formatting
ff <- ff %>% mutate(coll_date = case_when(grepl("/", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%m/%d/%Y")),
grepl("-", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%Y-%m-%d")),
T ~ NA_character_))
################################################################################
ff$IsolateID <- ""
ff$SegmentIDs <- ""
### strain naming: A/Michigan/UOM[sample_id]/2021
### {flu type A/B} / {collection state} / {UOM}{sample_id} / {collection year}
ff$StrainName <- ifelse(ff$received_source %in% c("CBR", "UHS", "EPIDIAV"), paste0("A/Michigan/UOM", ff$sample_id, "/", year(ff$coll_date)), "CHECK")
if (any(ff$StrainName == "CHECK")){
stop("Unexpected received source!")
}
ff$Subtype <- ifelse(ff$nextclade_HA_type == "H3", "H3N2", #H3N2
ifelse(ff$nextclade_HA_type == "H1", "H1N1", "CHECK")) #H1N1
if(any(ff$Subtype == "CHECK")){
stop("Issue with subtype assignment")
}
ff$Lineage <- ""
ff$Passage <- "ORI"
ff$Location <- "North America"
ff$Province <- "United States"
ff$SubProvince <- ""
ff$LocationAdditionalInfo <- ""
ff$Host <- "Human"
ff$HostAdditionalInfo <- ""
sequence_ids <- read.csv(paste0(seq_list_path, "gisaid_IDlist.csv")) %>% distinct()
sequence_ids <- separate(data = sequence_ids, col = IDS, sep = "\\_", into = c("sample_id", "segment", "platedate"), remove = FALSE)
#sequence_ids <- data.frame(sequence_ids) %>% select(IDS, sample_id, platedate, segment) %>% distinct()
sequence_ids <- reshape2::dcast(sequence_ids, sample_id + platedate ~ segment, value.var = c("IDS"))
sequence_ids <- sequence_ids %>% select(sample_id, HA, `NA`, PB1, PB2, PA, MP, NS, NP)
colnames(sequence_ids) <- c("sample_id", "SeqID_HA", "SeqID_NA", "SeqID_PB1", "SeqID_PB2", "SeqID_PA", "SeqID_MP", "SeqID_NS", "SeqID_NP")
ff <- merge(ff, sequence_ids, by = c("sample_id"))
ff$SeqID_HE <- ""
ff$SeqID_P3 <- ""
ff$SubmittingSampleID <- ""
ff$Authors <- ""
ff$OriginatingLabID <- "3201"
ff$OriginatingSampleID <- ""
ff$CollectionMonth <- ""
ff$CollectionYear <- ""
ff$CollectionDate <- ff$coll_date
ff_gisaid <- ff %>% select(IsolateID, SegmentIDs, StrainName, Subtype, Lineage,
Passage, Location, Province, SubProvince, LocationAdditionalInfo,
Host, HostAdditionalInfo, SeqID_HA, SeqID_NA, SeqID_PB1, SeqID_PB2,
SeqID_PA, SeqID_MP, SeqID_NS, SeqID_NP, SeqID_HE, SeqID_P3,
SubmittingSampleID, Authors, OriginatingLabID, OriginatingSampleID,
CollectionMonth, CollectionYear, CollectionDate)
ff_gisaid[is.na(ff_gisaid)] <- ""
write.csv(ff_gisaid, paste0("/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/SEQUENCING/INFLUENZA_A/5_GISAID_Uploads/upload_", plate_datef, "_iav_nanopore_run_", runnum, "/gisaid_base.csv"), row.names = FALSE, na = "")
library(tidyverse)
library(lubridate)
################################################################################
starting_path <- "/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
outputLOC <- paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/CDC_IVY_UPLOADS/")
seq_list <- read.csv(paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/full_compiled_data.csv"), colClasses = "character")
seq_list_o <- read.csv(paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/full_compiled_data.csv"), colClasses = "character")
seq_list <- seq_list %>% select(sample_id, subject_id, coll_date,
flag, received_source, SiteName, SampleBarcode,
PlateDate, PlatePlatform, PlateNumber,
pangolin_lineage, pangolin_probability, pangolin_status,
pangolin_note, nextclade_clade, nextclade_totalMissing,
nextclade_completeness, gisaid_strain, gisaid_epi_isl,
received_date, position,
PlateName, PlatePosition, SampleSourceLocation,
pangoLEARN_version, pangolin_conflict, pango_version,
pangolin_version, pangolin_runDate, PlateToPangolin_days,
nextclade_qcOverallScore, nextclade_qcOverallStatus, nextclade_totalMutations,
nextclade_totalNonACGTNs, nextclade_runDate, PlateToNextclade_days)
seq_list_o <- seq_list_o %>% select(sample_id, subject_id, coll_date,
flag, received_source, SiteName, SampleBarcode,
PlateDate, PlatePlatform, PlateNumber,
pangolin_lineage, pangolin_probability, pangolin_status,
pangolin_note, nextclade_clade, nextclade_totalMissing,
nextclade_completeness, gisaid_strain, gisaid_epi_isl,
received_date, position,
PlateName, PlatePosition, SampleSourceLocation,
pangoLEARN_version, pangolin_conflict, pango_version,
pangolin_version, pangolin_runDate, PlateToPangolin_days,
nextclade_qcOverallScore, nextclade_qcOverallStatus, nextclade_totalMutations,
nextclade_totalNonACGTNs, nextclade_runDate, PlateToNextclade_days)
seq_list <- filter(seq_list, received_source == "CDCIVY" | received_source == "CDCIVY4")
## check for CDC IVY 4 samples (start with 22, ivy 3 == 21)
if (any(substr(seq_list$subject_id, 1, 2) == 22)){
print("IVY 4 Samples Present, Need to separate for upload")
}
if (length(unique(seq_list$sample_id)) != nrow(seq_list)){
stop("Duplicate sample IDs - handle accordingly")
}
## remove study withdraws
seq_list <- filter(seq_list, flag != "Withdrawn from study")
################################################################################
### fix date formatting
seq_list <- seq_list %>% mutate(coll_date = case_when(grepl("/", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%m/%d/%Y")),
grepl("-", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%Y-%m-%d")),
T ~ NA_character_))
seq_list_o <- seq_list_o %>% mutate(coll_date = case_when(grepl("/", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%m/%d/%Y")),
grepl("-", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%Y-%m-%d")),
T ~ NA_character_))
qpcr <- seq_list %>% select(sample_id, subject_id, coll_date, PlateName, PlatePosition)
qpcr_full <- filter(seq_list_o, PlateName %in% unique(qpcr$PlateName)) %>% select(sample_id, subject_id, coll_date, PlateName, PlatePosition, received_source, flag)
pmc <- read.csv("/Users/juliegil/Documents/LauringLab_Code/plate_map_cross.csv")
hv <- read.csv("/Users/juliegil/Documents/LauringLab_Code/horizonal_vertical_by_plate.csv")
hv <- hv %>% select(processing.plate, order_plate)
# match plate to horiz/vertical arrangement
qpcr_full <- merge(qpcr_full, hv, by.x = c("PlateName"), by.y = c("processing.plate"), all.x = TRUE)
qpcr_full <- merge(qpcr_full, pmc, by.x = c("PlatePosition", "order_plate"), by.y = c("Slot", "PlateOrder"), all.x = TRUE)
qpcr_full$wellgrid <- paste0(qpcr_full$Letter, qpcr_full$Number)
qpcr_full <- qpcr_full %>% arrange(PlateName, Letter, Number)
write.csv(qpcr_full, "/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/SEQUENCING/SARSCOV2/8_QPCR_IVY/IVY_Locations/ivy_mapping.csv", row.names = FALSE, na = "")
colnames(seq_list) <- tolower(colnames(seq_list))
# add leading zero to month
if (nchar(month(Sys.Date())) == 1){
m <- paste0("0", month(Sys.Date()))
} else {
m <- month(Sys.Date())
}
# add leading zero to day
if (nchar(day(Sys.Date())) == 1){
d <- paste0("0", day(Sys.Date()))
} else {
d <- day(Sys.Date())
}
today <- paste0(year(Sys.Date()), m, d)
ivy3 <- filter(seq_list, substr(subject_id, 1, 2) == 21)
ivy4 <- filter(seq_list, substr(subject_id, 1, 2) == 22)
# change subject_id to study_id
ivy4 <- ivy4 %>% select(sample_id, subject_id, coll_date,
flag, received_source, sitename, samplebarcode,
platedate, plateplatform, platenumber,
pangolin_lineage, pangolin_status, pangolin_note,
nextclade_clade, nextclade_totalmissing, nextclade_completeness,
gisaid_strain, gisaid_epi_isl, received_date, position, platename,
plateposition, samplesourcelocation, pangolearn_version,
pango_version, pangolin_version, nextclade_qcoverallscore, nextclade_qcoverallstatus,
nextclade_totalmutations, nextclade_totalnonacgtns)
names(ivy4)[names(ivy4) == 'subject_id'] <- 'study_id'
#seq_list <- filter(seq_list, platenumber <= 49)
write.csv(ivy3, paste0(outputLOC, "cdc_ivy3_", today, ".csv"), row.names = FALSE, na = "")
write.csv(ivy4, paste0(outputLOC, "cdc_ivy4_", today, ".csv"), row.names = FALSE, na = "")
library(tidyverse)
library(lubridate)
################################################################################
starting_path <- "/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
outputLOC <- paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/RVTN_UPLOADS/")
seq_list <- read.csv(paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/full_compiled_data.csv"), colClasses = "character")
seq_list <- seq_list %>% select(sample_id, subject_id, coll_date,
flag, received_source, SiteName, SampleBarcode,
PlateDate, PlatePlatform, PlateNumber,
pangolin_lineage, pangolin_probability, pangolin_status,
pangolin_note, nextclade_clade, nextclade_totalMissing,
nextclade_completeness, gisaid_strain, gisaid_epi_isl,
received_date, position,
PlateName, PlatePosition, SampleSourceLocation,
pangoLEARN_version, pangolin_conflict, pango_version,
pangolin_version, pangolin_runDate, PlateToPangolin_days,
nextclade_qcOverallScore, nextclade_qcOverallStatus, nextclade_totalMutations,
nextclade_totalNonACGTNs, nextclade_runDate, PlateToNextclade_days)
seq_list <- filter(seq_list, received_source == "RVTN")
if (length(unique(seq_list$sample_id)) != nrow(seq_list)){
stop("Duplicate sample IDs - handle accordingly")
}
################################################################################
### fix date formatting
seq_list <- seq_list %>% mutate(coll_date = case_when(grepl("/", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%m/%d/%Y")),
grepl("-", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%Y-%m-%d")),
T ~ NA_character_))
colnames(seq_list) <- tolower(colnames(seq_list))
# add leading zero to month
if (nchar(month(Sys.Date())) == 1){
m <- paste0("0", month(Sys.Date()))
} else {
m <- month(Sys.Date())
}
# add leading zero to day
if (nchar(day(Sys.Date())) == 1){
d <- paste0("0", day(Sys.Date()))
} else {
d <- day(Sys.Date())
}
today <- paste0(year(Sys.Date()), m, d)
rvtn <- seq_list %>% select(sample_id, subject_id, coll_date,
flag, received_source, sitename, samplebarcode,
platedate, plateplatform, platenumber,
pangolin_lineage, pangolin_status,
pangolin_note, nextclade_clade, nextclade_totalmissing,
nextclade_completeness, gisaid_strain, gisaid_epi_isl,
received_date, position, platename, plateposition, samplesourcelocation,
pangolearn_version,
pango_version, pangolin_version,  nextclade_qcoverallscore, nextclade_qcoverallstatus,
nextclade_totalmutations, nextclade_totalnonacgtns)
#seq_list <- filter(seq_list, platenumber <= 49)
write.csv(rvtn, paste0(outputLOC, "rvtn_", today, ".csv"), row.names = FALSE, na = "")
getwd()
checking_wd <- getwd()
shiny::runApp('~/Documents/git_synced_code/misapphire_share')
library(tidyverse)
library(rvest)
library(openxlsx)
# read the html of the state website:
state_page <- read_html("https://www.michigan.gov/coronavirus/stats")
# get a list of all the html a nodes, where the urls are kept
state_a <- html_notes(state_page, "a")
# get a list of all the html a nodes, where the urls are kept
state_a <- html_nodes(state_page, "a")
# find the a node that has the phrase we care about
phrase_of_interest <- "Cases and Deaths by County by Date of Onset of Symptoms and Date of Death"
for (i in state_a){
if (grepl(phrase_of_interest, i)){
keep_url <- i
}
}
i
len(state_a)
length(state_a)
for (i in seq(1,length(state_a))){
if (grepl(phrase_of_interest, as.character(state_a[[i]]))){
keep_url <- as.character(state_a[[i]])
}
}
i
# find the a node that has the phrase we care about
phrase_of_interest <- "Onset of Symptoms"
for (i in seq(1,length(state_a))){
if (grepl(phrase_of_interest, as.character(state_a[[i]]))){
keep_url <- as.character(state_a[[i]])
}
}
i <- gsub("\\", "", as.character(i), fixed = TRUE)
i <- gsub("\\", "", as.character(keep_url), fixed = TRUE)
get_doc_url <- strsplit(i, ".xlsx")[[1]][1]
get_doc_url <- strsplit(get_doc_url, '.href=\"')[[1]][2]
doc_url <- substr(get_doc_url, 2, nchar(get_doc_url))
url <- paste0("https://www.michigan.gov/", doc_url, ".xlsx")
getwd()
# set where you'd like to download the file to:
output_filepath <- "/Users/juliegil/Documents/git_synced_code/misapphire_share/data/"
# set the file name of what you're downloading:
save_file_name <- "cases_deaths_by_county_state_of_michigan_20220420.xlsx"
# read the html of the state website:
state_page <- read_html("https://www.michigan.gov/coronavirus/stats")
# get a list of all the html a nodes, where the urls are kept
state_a <- html_nodes(state_page, "a")
# find the a node that has the phrase we care about
phrase_of_interest <- "Onset of Symptoms"
for (i in seq(1,length(state_a))){
if (grepl(phrase_of_interest, as.character(state_a[[i]]))){
keep_url <- as.character(state_a[[i]])
} else {
print("Phrase of Interest not in a nodes.")
}
}
i <- gsub("\\", "", as.character(keep_url), fixed = TRUE)
get_doc_url <- strsplit(i, ".xlsx")[[1]][1]
get_doc_url <- strsplit(get_doc_url, '.href=\"')[[1]][2]
doc_url <- substr(get_doc_url, 2, nchar(get_doc_url))
for (i in seq(1,length(state_a))){
if (grepl(phrase_of_interest, as.character(state_a[[i]]))){
keep_url <- as.character(state_a[[i]])
} else {
print("\\.")
}
}
# find the a node that has the phrase we care about
phrase_of_interest <- "Onset of Symptoms"
for (i in seq(1,length(state_a))){
if (grepl(phrase_of_interest, as.character(state_a[[i]]))){
keep_url <- as.character(state_a[[i]])
} else {
print(".")
}
}
for (i in seq(1,length(state_a))){
if (grepl(phrase_of_interest, as.character(state_a[[i]]))){
keep_url <- as.character(state_a[[i]])
}
}
i <- gsub("\\", "", as.character(keep_url), fixed = TRUE)
get_doc_url <- strsplit(i, ".xlsx")[[1]][1]
get_doc_url <- strsplit(get_doc_url, '.href=\"')[[1]][2]
doc_url <- substr(get_doc_url, 2, nchar(get_doc_url))
url <- paste0("https://www.michigan.gov/", doc_url, ".xlsx")
download.file(url, paste0(output_filepath, save_file_name), mode = "wb")
# read in the excel file you just created
excel_in <- read.xlsx(paste0(output_filepath, save_file_name), sheet = 1)
View(excel_in)
# read in the excel file you just created
excel_in <- read.xlsx(paste0(output_filepath, save_file_name), sheet = 1, detectDates = TRUE)
# write out the data into a csv instead
new_file_name_and_loc <- gsub(".xlsx", ".csv", paste0(output_filepath, save_file_name))
# and delete the excel version
file.remove(paste0(output_filepath, save_file_name))
library(tidyverse)
library(lubridate)
library(janitor)
#library(openxlsx)
################################################################################
#                   GISAID Files - Upload and Data Checks                      #
################################################################################
# gisaid file path
gisaid_fp <- paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/SequenceOutcomes/gisaid")
### output location of gisaid files, all together
outputLOC <- paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/SequenceOutcomes/SequenceOutcomeComplete")
################################################################################
file_list <- list.files(pattern = "*.tsv", path = gisaid_fp)
## check here - there should only be one .tsv file in this folder location, the most
# current gisaid file
if (length(file_list) != 1){
stop(paste0("There is more than one .tsv file in ", gisaid_fp))
}
checking_wd <- getwd()
if (grepl("juliegil", checking_wd)){
#starting_path <- "C:/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
starting_path <- "/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
#code_path <- "C:/Users/juliegil/Documents/UofM_Work/SequenceCompilationCode/"
code_path <- "/Users/juliegil/Documents/git_synced_code/SequenceCompilationCode/COVID19SequenceCompile/"
#batch_path <- "C:/Users/juliegil/Documents/UofM_Work/Lauring_Lab/Lab_Organization/AlertCode"
batch_path <- "/Users/juliegil/Documents/LauringLab_Code/AlertCode"
#influenza_path <- "C:/Users/juliegil/Documents/UofM_Work/SequenceCompilationCode/InfluenzaACode/"
influenza_path <- "/Users/juliegil/Documents/git_synced_code/SequenceCompilationCode/COVID19SequenceCompile/InfluenzaACode/"
} else if (grepl("leighbaker", checking_wd)){
starting_path <- "/Users/leighbaker/Dropbox (University of Michigan)/MED-LauringLab/"
code_path <- "/Users/leighbaker/Documents/Lauring_Lab/COVID19SequenceCompile/"
batch_path <- "/Users/leighbaker/Documents/Lauring_Lab/AlertCode"
} else {
print("User not recognized.")
}
options(scipen=999)
source(paste0(code_path, "pipeline_functions.R"))
library(tidyverse)
library(lubridate)
library(janitor)
#library(openxlsx)
################################################################################
#                   GISAID Files - Upload and Data Checks                      #
################################################################################
# gisaid file path
gisaid_fp <- paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/SequenceOutcomes/gisaid")
### output location of gisaid files, all together
outputLOC <- paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/SequenceOutcomes/SequenceOutcomeComplete")
################################################################################
file_list <- list.files(pattern = "*.tsv", path = gisaid_fp)
## check here - there should only be one .tsv file in this folder location, the most
# current gisaid file
if (length(file_list) != 1){
stop(paste0("There is more than one .tsv file in ", gisaid_fp))
}
gisaid_storage <- read.delim(paste0(gisaid_fp, "/", file_list[1]))
# remove any empty rows/columns that may come in
gisaid_storage <- remove_empty(gisaid_storage)
a <- filter(gisaid_storage, grepl("10042961500", Virus.name))
a <- filter(gisaid_storage, Virus.name == "hCoV-19/USA/MI-UM-10042961500/2021")
################################################################################
#          Creation of GISAID Dataset for COVID-19 Genetic Sampling            #
#                         Last Updated: 05/18/2021                             #
#                 Code Edited By: Julie (Jules) Gilbert                        #
################################################################################
library(tidyverse)
library(lubridate)
library(janitor)
#library(openxlsx)
################################################################################
#                   GISAID Files - Upload and Data Checks                      #
################################################################################
# gisaid file path
gisaid_fp <- paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/SequenceOutcomes/gisaid")
### output location of gisaid files, all together
outputLOC <- paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/SequenceOutcomes/SequenceOutcomeComplete")
################################################################################
file_list <- list.files(pattern = "*.tsv", path = gisaid_fp)
## check here - there should only be one .tsv file in this folder location, the most
# current gisaid file
if (length(file_list) != 1){
stop(paste0("There is more than one .tsv file in ", gisaid_fp))
}
gisaid_storage <- read.delim(paste0(gisaid_fp, "/", file_list[1]))
# remove any empty rows/columns that may come in
gisaid_storage <- remove_empty(gisaid_storage)
a <- filter(gisaid_storage, Virus.name == "hCoV-19/USA/MI-UM-10042961500/2021")
a <- filter(gisaid_storage, grepl("10042961500", Virus.name))
# select columns we care about
gisaid_storage <- gisaid_storage %>% select(Virus.name, Accession.ID, Clade, Pango.lineage)
# create sample_id column
gisaid_storage$sample_id <-  sapply(strsplit(as.character(gisaid_storage$Virus.name),'/'), "[", 3)
gisaid_storage <- filter(gisaid_storage, grepl("MI-UM", Virus.name) | grepl("IVY", Virus.name) | grepl("RVTN", Virus.name))
View(gisaid_storage)
filter(gisaid_storage, Accession.ID == "EPI_ISL_8316986")
filter(gisaid_storage, grepl(61500, Virus.name))
filter(gisaid_storage, grepl("61500", Virus.name))

write.csv(ivy4, paste0(outputLOC, "cdc_ivy4_", today, ".csv"), row.names = FALSE, na = "")
View(a)
checking_wd <- getwd()
if (grepl("juliegil", checking_wd)){
starting_path <- "C:/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
#starting_path <- "/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
code_path <- "C:/Users/juliegil/Documents/UofM_Work/SequenceCompilationCode/"
#code_path <- "/Users/juliegil/Documents/git_synced_code/SequenceCompilationCode/COVID19SequenceCompile/"
batch_path <- "C:/Users/juliegil/Documents/UofM_Work/Lauring_Lab/Lab_Organization/AlertCode"
#batch_path <- "/Users/juliegil/Documents/LauringLab_Code/AlertCode"
influenza_path <- "C:/Users/juliegil/Documents/UofM_Work/SequenceCompilationCode/InfluenzaACode/"
#influenza_path <- "/Users/juliegil/Documents/git_synced_code/SequenceCompilationCode/COVID19SequenceCompile/InfluenzaACode/"
} else if (grepl("leighbaker", checking_wd)){
starting_path <- "/Users/leighbaker/Dropbox (University of Michigan)/MED-LauringLab/"
code_path <- "/Users/leighbaker/Documents/Lauring_Lab/COVID19SequenceCompile/"
batch_path <- "/Users/leighbaker/Documents/Lauring_Lab/AlertCode"
} else {
print("User not recognized.")
}
checking_wd <- getwd()
if (grepl("juliegil", checking_wd)){
#starting_path <- "C:/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
starting_path <- "/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
#code_path <- "C:/Users/juliegil/Documents/UofM_Work/SequenceCompilationCode/"
code_path <- "/Users/juliegil/Documents/git_synced_code/SequenceCompilationCode/COVID19SequenceCompile/"
#batch_path <- "C:/Users/juliegil/Documents/UofM_Work/Lauring_Lab/Lab_Organization/AlertCode"
batch_path <- "/Users/juliegil/Documents/LauringLab_Code/AlertCode"
#influenza_path <- "C:/Users/juliegil/Documents/UofM_Work/SequenceCompilationCode/InfluenzaACode/"
influenza_path <- "/Users/juliegil/Documents/git_synced_code/SequenceCompilationCode/COVID19SequenceCompile/InfluenzaACode/"
} else if (grepl("leighbaker", checking_wd)){
starting_path <- "/Users/leighbaker/Dropbox (University of Michigan)/MED-LauringLab/"
code_path <- "/Users/leighbaker/Documents/Lauring_Lab/COVID19SequenceCompile/"
batch_path <- "/Users/leighbaker/Documents/Lauring_Lab/AlertCode"
} else {
print("User not recognized.")
}
options(scipen=999)
source(paste0(code_path, "pipeline_functions.R"))
library(tidyverse)
library(lubridate)
################################################################################
starting_path <- "/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
outputLOC <- paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/CDC_IVY_UPLOADS/")
seq_list <- read.csv(paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/full_compiled_data.csv"), colClasses = "character")
seq_list_o <- read.csv(paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/full_compiled_data.csv"), colClasses = "character")
################################################################################
seq_list <- seq_list %>% select(sample_id, subject_id, coll_date,
flag, received_source, SiteName, SampleBarcode,
PlateDate, PlatePlatform, PlateNumber,
pangolin_lineage, pangolin_probability, pangolin_status,
pangolin_note, nextclade_clade, nextclade_totalMissing,
nextclade_completeness, gisaid_strain, gisaid_epi_isl,
received_date, position,
PlateName, PlatePosition, SampleSourceLocation,
pangoLEARN_version, pangolin_conflict, pango_version,
pangolin_version, pangolin_runDate, PlateToPangolin_days,
nextclade_qcOverallScore, nextclade_qcOverallStatus, nextclade_totalMutations,
nextclade_totalNonACGTNs, nextclade_runDate, PlateToNextclade_days)
seq_list_o <- seq_list_o %>% select(sample_id, subject_id, coll_date,
flag, received_source, SiteName, SampleBarcode,
PlateDate, PlatePlatform, PlateNumber,
pangolin_lineage, pangolin_probability, pangolin_status,
pangolin_note, nextclade_clade, nextclade_totalMissing,
nextclade_completeness, gisaid_strain, gisaid_epi_isl,
received_date, position,
PlateName, PlatePosition, SampleSourceLocation,
pangoLEARN_version, pangolin_conflict, pango_version,
pangolin_version, pangolin_runDate, PlateToPangolin_days,
nextclade_qcOverallScore, nextclade_qcOverallStatus, nextclade_totalMutations,
nextclade_totalNonACGTNs, nextclade_runDate, PlateToNextclade_days)
seq_list <- filter(seq_list, received_source == "CDCIVY" | received_source == "CDCIVY4")
## check for CDC IVY 4 samples (start with 22, ivy 3 == 21)
if (any(substr(seq_list$subject_id, 1, 2) == 22)){
print("IVY 4 Samples Present, Need to separate for upload")
}
if (length(unique(seq_list$sample_id)) != nrow(seq_list)){
stop("Duplicate sample IDs - handle accordingly")
}
## remove study withdraws
seq_list <- filter(seq_list, flag != "Withdrawn from study")
################################################################################
### fix date formatting
seq_list <- seq_list %>% mutate(coll_date = case_when(grepl("/", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%m/%d/%Y")),
grepl("-", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%Y-%m-%d")),
T ~ NA_character_))
seq_list_o <- seq_list_o %>% mutate(coll_date = case_when(grepl("/", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%m/%d/%Y")),
grepl("-", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%Y-%m-%d")),
T ~ NA_character_))
################################################################################
# create portion for qPCR matching
qpcr <- seq_list %>% select(sample_id, subject_id, coll_date, PlateName, PlatePosition)
qpcr_full <- filter(seq_list_o, PlateName %in% unique(qpcr$PlateName)) %>% select(sample_id, subject_id, coll_date, PlateName, PlatePosition, received_source, flag)
pmc <- read.csv("/Users/juliegil/Documents/LauringLab_Code/plate_map_cross.csv")
hv <- read.csv("/Users/juliegil/Documents/LauringLab_Code/horizonal_vertical_by_plate.csv")
hv <- hv %>% select(processing.plate, order_plate)
# match plate to horiz/vertical arrangement
qpcr_full <- merge(qpcr_full, hv, by.x = c("PlateName"), by.y = c("processing.plate"), all.x = TRUE)
qpcr_full <- merge(qpcr_full, pmc, by.x = c("PlatePosition", "order_plate"), by.y = c("Slot", "PlateOrder"), all.x = TRUE)
qpcr_full$wellgrid <- paste0(qpcr_full$Letter, qpcr_full$Number)
qpcr_full <- qpcr_full %>% arrange(PlateName, Letter, Number)
write.csv(qpcr_full, "/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/SEQUENCING/SARSCOV2/8_QPCR_IVY/IVY_Locations/ivy_mapping.csv", row.names = FALSE, na = "")
View(qpcr_full)
table(qpcr$PlateName)
table(qpcr_full$PlateName)
pmc <- read.csv("/Users/juliegil/Documents/LauringLab_Code/plate_map_cross.csv")
hv <- read.csv("/Users/juliegil/Documents/LauringLab_Code/horizonal_vertical_by_plate.csv")
table(hv$processing.plate)
################################################################################
#       Creation of CDC IVY Upload Dataset for COVID-19 Genetic Sampling       #
#                         Last Updated: 06/18/2021                             #
#                 Code Edited By: Julie (Jules) Gilbert                        #
################################################################################
library(tidyverse)
library(lubridate)
################################################################################
starting_path <- "/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
outputLOC <- paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/CDC_IVY_UPLOADS/")
seq_list <- read.csv(paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/full_compiled_data.csv"), colClasses = "character")
seq_list_o <- read.csv(paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/full_compiled_data.csv"), colClasses = "character")
################################################################################
seq_list <- seq_list %>% select(sample_id, subject_id, coll_date,
flag, received_source, SiteName, SampleBarcode,
PlateDate, PlatePlatform, PlateNumber,
pangolin_lineage, pangolin_probability, pangolin_status,
pangolin_note, nextclade_clade, nextclade_totalMissing,
nextclade_completeness, gisaid_strain, gisaid_epi_isl,
received_date, position,
PlateName, PlatePosition, SampleSourceLocation,
pangoLEARN_version, pangolin_conflict, pango_version,
pangolin_version, pangolin_runDate, PlateToPangolin_days,
nextclade_qcOverallScore, nextclade_qcOverallStatus, nextclade_totalMutations,
nextclade_totalNonACGTNs, nextclade_runDate, PlateToNextclade_days)
seq_list_o <- seq_list_o %>% select(sample_id, subject_id, coll_date,
flag, received_source, SiteName, SampleBarcode,
PlateDate, PlatePlatform, PlateNumber,
pangolin_lineage, pangolin_probability, pangolin_status,
pangolin_note, nextclade_clade, nextclade_totalMissing,
nextclade_completeness, gisaid_strain, gisaid_epi_isl,
received_date, position,
PlateName, PlatePosition, SampleSourceLocation,
pangoLEARN_version, pangolin_conflict, pango_version,
pangolin_version, pangolin_runDate, PlateToPangolin_days,
nextclade_qcOverallScore, nextclade_qcOverallStatus, nextclade_totalMutations,
nextclade_totalNonACGTNs, nextclade_runDate, PlateToNextclade_days)
seq_list <- filter(seq_list, received_source == "CDCIVY" | received_source == "CDCIVY4")
## check for CDC IVY 4 samples (start with 22, ivy 3 == 21)
if (any(substr(seq_list$subject_id, 1, 2) == 22)){
print("IVY 4 Samples Present, Need to separate for upload")
}
if (length(unique(seq_list$sample_id)) != nrow(seq_list)){
stop("Duplicate sample IDs - handle accordingly")
}
## remove study withdraws
seq_list <- filter(seq_list, flag != "Withdrawn from study")
################################################################################
### fix date formatting
seq_list <- seq_list %>% mutate(coll_date = case_when(grepl("/", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%m/%d/%Y")),
grepl("-", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%Y-%m-%d")),
T ~ NA_character_))
seq_list_o <- seq_list_o %>% mutate(coll_date = case_when(grepl("/", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%m/%d/%Y")),
grepl("-", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%Y-%m-%d")),
T ~ NA_character_))
################################################################################
# create portion for qPCR matching
qpcr <- seq_list %>% select(sample_id, subject_id, coll_date, PlateName, PlatePosition)
qpcr_full <- filter(seq_list_o, PlateName %in% unique(qpcr$PlateName)) %>% select(sample_id, subject_id, coll_date, PlateName, PlatePosition, received_source, flag)
pmc <- read.csv("/Users/juliegil/Documents/LauringLab_Code/plate_map_cross.csv")
hv <- read.csv("/Users/juliegil/Documents/LauringLab_Code/horizonal_vertical_by_plate.csv")
hv <- hv %>% select(processing.plate, order_plate)
# match plate to horiz/vertical arrangement
qpcr_full <- merge(qpcr_full, hv, by.x = c("PlateName"), by.y = c("processing.plate"), all.x = TRUE)
qpcr_full <- merge(qpcr_full, pmc, by.x = c("PlatePosition", "order_plate"), by.y = c("Slot", "PlateOrder"), all.x = TRUE)
qpcr_full$wellgrid <- paste0(qpcr_full$Letter, qpcr_full$Number)
qpcr_full <- qpcr_full %>% arrange(PlateName, Letter, Number)
write.csv(qpcr_full, "/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/SEQUENCING/SARSCOV2/8_QPCR_IVY/IVY_Locations/ivy_mapping.csv", row.names = FALSE, na = "")
table(qpcr_full$PlateName)
head(seq_list)
seq_list <- read.csv(paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/full_compiled_data.csv"), colClasses = "character")
head(seq_list)
checking_wd <- getwd()
if (grepl("juliegil", checking_wd)){
#starting_path <- "C:/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
starting_path <- "/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
#code_path <- "C:/Users/juliegil/Documents/UofM_Work/SequenceCompilationCode/"
code_path <- "/Users/juliegil/Documents/git_synced_code/SequenceCompilationCode/COVID19SequenceCompile/"
#batch_path <- "C:/Users/juliegil/Documents/UofM_Work/Lauring_Lab/Lab_Organization/AlertCode"
batch_path <- "/Users/juliegil/Documents/LauringLab_Code/AlertCode"
#influenza_path <- "C:/Users/juliegil/Documents/UofM_Work/SequenceCompilationCode/InfluenzaACode/"
influenza_path <- "/Users/juliegil/Documents/git_synced_code/SequenceCompilationCode/COVID19SequenceCompile/InfluenzaACode/"
} else if (grepl("leighbaker", checking_wd)){
starting_path <- "/Users/leighbaker/Dropbox (University of Michigan)/MED-LauringLab/"
code_path <- "/Users/leighbaker/Documents/Lauring_Lab/COVID19SequenceCompile/"
batch_path <- "/Users/leighbaker/Documents/Lauring_Lab/AlertCode"
} else if (grepl("leighbak", checking_wd)){
starting_path <- "/Users/leighbak/Dropbox (University of Michigan)/MED-LauringLab/"
code_path <- "/Users/leighbak/Documents/Lauring_Lab/COVID19SequenceCompile/"
batch_path <- "/Users/leighbak/Documents/Lauring_Lab/AlertCode"
} else {
print("User not recognized.")
}
options(scipen=999)
source(paste0(code_path, "pipeline_functions.R"))
# sars-cov-2 plate
plate_name <- "20220524_SC2_Nanopore_Run_174"
# load libraries
library(tidyverse)
library(lubridate)
################################################################################
# set paths
#starting_path <- "C:/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
#"/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
## set run folder accordingly
outputLOC <- paste0(starting_path, "SEQUENCING/SARSCOV2/3_ProcessedGenomes/", plate_name, "/")
# read in compiled dataset
seq_list <- read.csv(paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/full_compiled_data.csv"), colClasses = "character")
################################################################################
# filter to plate run
seq_list2 <- filter(seq_list, PlateNumber == strsplit(plate_name, "_")[[1]][5] & PlateDate == paste0(substr(strsplit(plate_name, "_")[[1]][1], 1, 4), "-", substr(strsplit(plate_name, "_")[[1]][1], 5, 6), "-", substr(strsplit(plate_name, "_")[[1]][1], 7, 8)))
table(year(seq_list2$coll_date))
table(year(as.date(seq_list2$coll_date)))
table(year(as_date(seq_list2$coll_date)))
sample_years <- unique(year(as_date(seq_list2$coll_date)))
current_year <- year(Sys.Date())
sample_years <- unique(year(as_date(seq_list2$coll_date)))
current_year <- year(Sys.Date())
any(sample_years != current_year)
any(!sample_years %in% current_year)
sample_years
sample_years <- unique(year(as_date(seq_list2$coll_date)))
sample_years <- sample_years[!is.na(sample_years)] # have to remove NA from control well rows date listing
current_year <- year(Sys.Date())
any(!sample_years %in% current_year)
# sars-cov-2 plate
plate_name <- "20220531_SC2_Nanopore_Run_175"
################################################################################
#       Creation of Subsetting Compiled File for FASTA Name Replacement        #
#                         Last Updated: 06/02/2021                             #
#                 Code Edited By: Julie (Jules) Gilbert                        #
################################################################################
# load libraries
library(tidyverse)
library(lubridate)
################################################################################
# set paths
#starting_path <- "C:/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
#"/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
## set run folder accordingly
outputLOC <- paste0(starting_path, "SEQUENCING/SARSCOV2/3_ProcessedGenomes/", plate_name, "/")
# read in compiled dataset
seq_list <- read.csv(paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/full_compiled_data.csv"), colClasses = "character")
################################################################################
# filter to plate run
seq_list2 <- filter(seq_list, PlateNumber == strsplit(plate_name, "_")[[1]][5] & PlateDate == paste0(substr(strsplit(plate_name, "_")[[1]][1], 1, 4), "-", substr(strsplit(plate_name, "_")[[1]][1], 5, 6), "-", substr(strsplit(plate_name, "_")[[1]][1], 7, 8)))
#puis <- filter(seq_list, grepl("pui", tolower(flag)) | grepl("pui", tolower(SampleSourceLocation)))
sample_years <- unique(year(as_date(seq_list2$coll_date)))
sample_years <- sample_years[!is.na(sample_years)] # have to remove NA from control well rows date listing
current_year <- year(Sys.Date())
if (any(!sample_years %in% current_year)){
message("Samples with collection dates not in current year")
}
show_samples <- filter(saq_list2, year(as_date(coll_date)) != current_year)
show_samples <- filter(seq_list2, year(as_date(coll_date)) != current_year)
View(show_samples)
if (any(!sample_years %in% current_year)){
message("Samples with collection dates not in current year")
show_samples <- filter(seq_list2, year(as_date(coll_date)) != current_year)
show_samples <- show_samples %>% select(sample_id, subject_id, coll_date, received_source, received_date)
message(show_samples)
}
message(as.data.frame(show_samples))
library(gt)
message(show_samples %>% gt())
print(show_samples %>% gt())
source(paste0(code_path, "OutsidePipeline/subset_compiled_for_fasta.R"))
source(paste0(code_path, "OutsidePipeline/subset_compiled_for_fasta.R"))
source(paste0(code_path, "OutsidePipeline/subset_compiled_for_fasta.R"))
letter_value <- readline(prompt="If you'd like to proceed, press y, if you'd like to stop, press n: ")
letter_value[1] == "n"
if (letter_value[1] == "n"){
stop()
}
source(paste0(code_path, "OutsidePipeline/subset_compiled_for_fasta.R"))
source(paste0(code_path, "OutsidePipeline/subset_compiled_for_fasta.R"))
library(tidyverse)
library(lubridate)
library(googlesheets4)
library(rvest)
library(openxlsx)
# read in google keys
source("/Users/juliegil/Documents/LauringLab_Code/code_for_misapphire_private_data_refresh/google_keys.R")
# let's read in our data samples
pat_file_loc <- "/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/External_Projects_DataRequests/SARSCOV2/MM_MDHHS_DataRequest/Returned/"
# get list of csv file names within pat_file_loc
patient_files <- list.files(pat_file_loc)
# read all patient files in to one large data frame
# set storage data frame
patf <- data.frame()
# create set of expected column names
expected_columns <- c(CLIAID = NA_character_ , PATIENT_LNAME = NA_character_, PATIENT_FNAME = NA_character_,
PATIENT_MNAME = NA_character_, PATIENT_ADDR1 = NA_character_, PATIENT_ADDR2 = NA_character_,
PATIENT_CITY = NA_character_, PATIENT_STATE = NA_character_, PATIENT_ZIP = NA_character_,
PATIENT_COUNTY = NA_character_, PATIENT_PHONE = NA_character_, PATIENT_DOB = NA_character_,
PATIENT_SEX = NA_character_, PATIENT_RACE = NA_character_, RACE_FND_DESC = NA_character_,
PATIENT_ETHNICITY = NA_character_, ETHNIC_GROUP_DESC = NA_character_, PATIENT_MRN = NA_character_,
ACCESSION_ID = NA_character_, SPECIMEN_SOURCE = NA_character_, TEST_NAME = NA_character_,
TEST_LOINC = NA_character_, RESULT = NA_character_, SPECIMEN_COLLECTION_DATE = NA_character_,
ORDER_DATE = NA_character_, ORDERING_FACILITY = NA_character_, PROVIDER_LNAME = NA_character_,
PROVIDER_FNAME = NA_character_, PROVIDER_PHONE = NA_character_, PROVIDER_ADDRESS1 = NA_character_,
PROVIDER_ADDRESS2 = NA_character_, PROVIDER_CITY = NA_character_, PROVIDER_STATE = NA_character_,
PROVIDER_ZIP = NA_character_)
for (i in patient_files){ # iterate through patient file names
f_in <- read.csv(paste0(pat_file_loc, i)) # read in the patient file
# check column names for weird symbols
column_names_check <- colnames(f_in) # get list of column names
column_names_check2 <- c() # make empty storage set for column names with symbols removed
for (each_name in column_names_check){ # iterate through list of column names
each_name <- ifelse("?" %in% each_name, gsub(pattern = "?..", replacement = "", x = each_name), each_name) # remove symbol and replace with nothing
column_names_check2 <- c(column_names_check2, each_name) # append to storage set
}
colnames(f_in) <- column_names_check2 # reassign cleaned column names
f_in <- add_column(f_in, !!!expected_columns[setdiff(names(expected_columns), names(f_in))]) # add in blank columns if names are missing
#print(colnames(f_in))
patf <- rbind(patf, f_in) # append it to storage set
}
# get subset relevant to this particular mcir pull
#patf <- filter(patf, as.numeric(PATIENT_MRN) %in% as.numeric(mcir_in$QRD_PATIENT_ID))
# select only subset of patient variables
# patf_details <- patf %>% select(PATIENT_MRN, PATIENT_SEX, PATIENT_ZIP, PATIENT_COUNTY, PATIENT_RACE, PATIENT_ETHNICITY, PATIENT_DOB) %>% distinct()
#
# # separate parts of date of birth
# patf_details$DOB_YEAR <- substr(patf_details$PATIENT_DOB, 1, 4)
# patf_details$DOB_MONTH <- substr(patf_details$PATIENT_DOB, 5, 6)
# patf_details$DOB_DAY <- substr(patf_details$PATIENT_DOB, 7, 8)
#
# # put date of birth parts into proper format (so R can read it as a date)
# patf_details$DOB_DATE <- as_date(paste0(patf_details$DOB_YEAR, "-", patf_details$DOB_MONTH, "-", patf_details$DOB_DAY))
#
# patf_details$APPROX_AGE <- floor((as_date("2021-02-01") - patf_details$DOB_DATE)/365)
####
# select subset of variables
patf_details2 <- patf %>% select(PATIENT_MRN, PATIENT_SEX, PATIENT_ZIP, PATIENT_COUNTY, PATIENT_RACE, PATIENT_ETHNICITY, PATIENT_DOB, RESULT, SPECIMEN_COLLECTION_DATE) %>% distinct()
# pull out parts of collection date
patf_details2$COLL_YEAR <- substr(patf_details2$SPECIMEN_COLLECTION_DATE, 1, 4)
patf_details2$COLL_MONTH <- substr(patf_details2$SPECIMEN_COLLECTION_DATE, 5, 6)
patf_details2$COLL_DAY <- substr(patf_details2$SPECIMEN_COLLECTION_DATE, 7, 8)
# place date parts into date format for R
patf_details2$COLL_DATE <- as_date(paste0(patf_details2$COLL_YEAR, "-", patf_details2$COLL_MONTH, "-", patf_details2$COLL_DAY))
# pull out parts of date of birth
patf_details2$DOB_YEAR <- substr(patf_details2$PATIENT_DOB, 1, 4)
patf_details2$DOB_MONTH <- substr(patf_details2$PATIENT_DOB, 5, 6)
patf_details2$DOB_DAY <- substr(patf_details2$PATIENT_DOB, 7, 8)
# place date parts into date format for R
patf_details2$DOB_DATE <- as_date(paste0(patf_details2$DOB_YEAR, "-", patf_details2$DOB_MONTH, "-", patf_details2$DOB_DAY))
# calculate approximate age at time of sample collection as days between collection date and date of birth
# divided by 365, and rounded down to the nearest integer
patf_details2$APPROX_AGE <- floor((as_date(patf_details2$COLL_DATE) - as_date(patf_details2$DOB_DATE))/365)
patf_details2$week <- epiweek(patf_details2$COLL_DATE) # get epidemiological week of the sample collection date
patf_details2$week <- ifelse(nchar(patf_details2$week) == 1, paste0("0", patf_details2$week), patf_details2$week) # add zero to week number if single digit
# if the week is 52 and day is in the new year, assign to the year prior to the collection date
# table(filter(patf_details2, week %in% c(51, 52, 53))$week, day(filter(patf_details2, week %in% c(51, 52, 53))$COLL_DATE))
patf_details2$collection_week <- ifelse(patf_details2$week >= "52" & patf_details2$COLL_DAY < 7, paste0(as.character(as.numeric(patf_details2$COLL_YEAR) - 1), "-", patf_details2$week),  paste0(as.character(patf_details2$COLL_YEAR), "-", patf_details2$week))
patf_details2 <- patf_details2 %>% mutate(extra_clade = case_when(RESULT == "B.1.1.529" ~ "Omicron",
grepl("BA.1", RESULT) ~ "Omicron BA.1 Type",
grepl("BA.2", RESULT) ~ "Omicron BA.2 Type",
grepl("BA.3", RESULT) ~ "Omicron BA.3 Type",
grepl("BA.4", RESULT) ~ "Omicron BA.4 Type",
grepl("BA.5", RESULT) ~ "Omicron BA.5 Type",
grepl("AY.", RESULT) ~ "Delta",
RESULT == "B.1.617.2" ~ "Delta",
RESULT == "B.1.1.7" ~ "Alpha",
grepl("Q.", RESULT) ~ "Alpha",
RESULT == "B.1.351" ~ "Beta",
RESULT == "P.1" ~ "Gamma",
RESULT == "B.1.427" ~ "Epsilon",
RESULT == "B.1.429" ~ "Epsilon",
RESULT == "B.1.525" ~ "Eta",
RESULT == "B.1.526" ~ "Iota",
RESULT == "B.1.617.1" ~ "Kappa",
RESULT == "B.1.621" ~ "Mu",
RESULT == "B.1.621.1" ~ "Mu",
RESULT == "P.2" ~ "Zeta",
grepl("B.", RESULT) ~ "Original B",
RESULT == "B" ~ "Original B",
RESULT == "D.2" ~ "Original B",
RESULT == "R.1" ~ "Original B",
RESULT == "C.37" ~ "Original B",
grepl("A.", RESULT) ~ "Original A",
RESULT == "A" ~ "Original A",
RESULT == "" ~ "No Call",
RESULT == "None" ~ "No Call",
RESULT == "Unassigned" ~ "No Call",
T ~ "Unknown"))
#colnames(patf_details2)
patf_details2 <- patf_details2 %>% select(PATIENT_MRN, PATIENT_SEX, PATIENT_ZIP, PATIENT_COUNTY, PATIENT_RACE, PATIENT_ETHNICITY, RESULT, COLL_MONTH, COLL_DATE, APPROX_AGE, collection_week, extra_clade)
#patf_details2 <- patf_details2 %>% mutate(PATIENT_MRN = paste0("10", PATIENT_MRN, "01"))
patf_details2 <- patf_details2 %>% mutate(PATIENT_RACE = case_when(PATIENT_RACE == "W" ~ "White or Caucasian",
PATIENT_RACE == "B" ~ "Black or African American",
PATIENT_RACE == "O" ~ "Other",
PATIENT_RACE == "U" ~ "Unknown",
PATIENT_RACE == "A" ~ "Asian",
PATIENT_RACE == "M" ~ "Multiple",
PATIENT_RACE == "I" ~ "American Indian and Alaska Native",
PATIENT_RACE == "D" ~ "Patient Refused",
PATIENT_RACE == "P" ~ "Native Hawaiian and Other Pacific Islander",
T ~ PATIENT_RACE))
patf_details2 <- patf_details2 %>% mutate(AGE_GROUP = case_when(APPROX_AGE < 18 ~ "Under 18",
APPROX_AGE >= 18 & APPROX_AGE < 30 ~ "18-29",
APPROX_AGE >= 30 & APPROX_AGE < 50 ~ "30-49",
APPROX_AGE >= 50 ~ "50+",
T ~ "Unknown"))
# set one
strain_by_sex <- patf_details2 %>% group_by(PATIENT_SEX, extra_clade, collection_week) %>% summarize(max_month = max(COLL_MONTH), count = length(unique(PATIENT_MRN)))
strain_by_sex$TYPE <- "BySex"
colnames(strain_by_sex) <- c("DEMO", "CLADETYPE", "WEEK", "MONTH", "COUNT", "TYPE")
# set two
strain_by_race <- patf_details2 %>% group_by(PATIENT_RACE, extra_clade, collection_week) %>% summarize(max_month = max(COLL_MONTH), count = length(unique(PATIENT_MRN)))
strain_by_race$TYPE <- "ByRace"
colnames(strain_by_race) <- c("DEMO", "CLADETYPE", "WEEK", "MONTH", "COUNT", "TYPE")
# set three
strain_by_eth <- patf_details2 %>% group_by(PATIENT_ETHNICITY, extra_clade, collection_week) %>% summarize(max_month = max(COLL_MONTH), count = length(unique(PATIENT_MRN)))
strain_by_eth$TYPE <- "ByEth"
colnames(strain_by_eth) <- c("DEMO", "CLADETYPE", "WEEK", "MONTH", "COUNT", "TYPE")
# set four
strain_by_age <- patf_details2 %>% group_by(AGE_GROUP, extra_clade, collection_week) %>% summarize(max_month = max(COLL_MONTH), count = length(unique(PATIENT_MRN)))
strain_by_age$TYPE <- "ByAge"
colnames(strain_by_age) <- c("DEMO", "CLADETYPE", "WEEK", "MONTH", "COUNT", "TYPE")
total_patient_details <- rbind(strain_by_age, strain_by_eth, strain_by_race, strain_by_sex)
#patf_details2$PATIENT_MRN <- lapply(patf_details2$PATIENT_MRN, function(x) {digest::digest(x, algo="md5", serialize = F)})
#total_patient_details <- total_patient_details %>% mutate(MONTH = month.abb[as.numeric(MONTH)])
total_patient_details <- total_patient_details %>% mutate(across(everything(), as.character))
write.csv(total_patient_details, "/Users/juliegil/Documents/LauringLab_Code/code_for_misapphire_private_data_refresh/patient_details.csv", row.names = FALSE, na = "")
write_sheet(data = total_patient_details, ss = patient_details_locale, sheet = "patient_details")
pd_zip <- patf_details2 %>% group_by(PATIENT_ZIP, extra_clade) %>% summarize(max_month = max(COLL_MONTH), count = length(unique(PATIENT_MRN)))
write.csv(pd_zip, "/Users/juliegil/Documents/LauringLab_Code/code_for_misapphire_private_data_refresh/zip_data.csv", row.names = FALSE, na = "")
write_sheet(data = pd_zip, ss = zip_data_locale, sheet = "zip_data")
pd_county <- patf_details2 %>% group_by(PATIENT_COUNTY, extra_clade, collection_week) %>% summarize(max_month = max(COLL_MONTH),
count = length(unique(PATIENT_MRN)),
#pieces = length(unique(RESULT)),
pieces2 = toString(unique(RESULT)))
write.csv(pd_county, "/Users/juliegil/Documents/LauringLab_Code/code_for_misapphire_private_data_refresh/county_data.csv", row.names = FALSE, na = "")
write_sheet(data = pd_county, ss = county_data_locale, sheet = "county_data")
# set where you'd like to download the file to:
output_filepath <- "/Users/juliegil/Documents/git_synced_code/misapphire_private_moved/misapphire_private/data/"
# set the file name of what you're downloading:
save_file_name <- "state_county_data.xlsx"
# read the html of the state website:
state_page <- read_html("https://www.michigan.gov/coronavirus/stats")
# get a list of all the html a nodes, where the urls are kept
state_a <- html_nodes(state_page, "a")
# find the a node that has the phrase we care about
phrase_of_interest <- "Onset of Symptoms"
for (i in seq(1,length(state_a))){
if (grepl(phrase_of_interest, as.character(state_a[[i]]))){
keep_url <- as.character(state_a[[i]])
}
}
# get the portion of the url from the a node that we care about, to make the data pull
i <- gsub("\\", "", as.character(keep_url), fixed = TRUE)
get_doc_url <- strsplit(i, ".xlsx")[[1]][1]
get_doc_url <- strsplit(get_doc_url, '.href=\"')[[1]][2]
doc_url <- substr(get_doc_url, 2, nchar(get_doc_url))
url <- paste0("https://www.michigan.gov/", doc_url, ".xlsx")
download.file(url, paste0(output_filepath, save_file_name), mode = "wb")
# read in the excel file you just created
excel_in <- read.xlsx(paste0(output_filepath, save_file_name), sheet = 1, detectDates = TRUE)
# write out the data into a csv instead
new_file_name_and_loc <- gsub(".xlsx", ".csv", paste0(output_filepath, save_file_name))
write.csv(excel_in, new_file_name_and_loc, row.names = FALSE, na = "")
# and delete the excel version
file.remove(paste0(output_filepath, save_file_name))
covid_cases_county <- read.csv(paste0(output_filepath, "state_county_data.csv")) # read in that data we just created
# create date and epi week columns
covid_cases_county <- filter(covid_cases_county, CASE_STATUS == "Confirmed") %>% mutate(Date = substr(Date, 1, 10),
week = epiweek(as_date(Date)))
# filter the data down to match available patient data range
covid_cases_county <- filter(covid_cases_county, as_date(Date) >= min(as_date(patf_details2$COLL_DATE)) & as_date(Date) <= max(as_date(patf_details2$COLL_DATE)))
covid_cases_county <- covid_cases_county %>% mutate(week = case_when(nchar(as.character(week)) == 1 ~ paste0("0", week),
T ~ as.character(week)),
case_week = case_when(week >= "52" & day(as_date(Date)) < 7 ~ paste0(year(as_date(Date)) - 1, "-", week),
T ~ paste0(year(as_date(Date)), "-", week)))
covid_cases_county2 <- covid_cases_county %>% mutate(COUNTY = case_when(COUNTY == "Detroit City" ~ "Wayne",
T ~ COUNTY))
covid_cases_county <- covid_cases_county %>% group_by(COUNTY, case_week) %>% summarize(confirmed_cases = sum(Cases, na.rm = TRUE))
covid_cases_2S <- filter(covid_cases_county, COUNTY %in% c("Wayne", "Washtenaw", "Detroit City", "Monroe")) %>% mutate(COUNTY = "Region 2S") %>% group_by(COUNTY, case_week) %>% summarize(confirmed_cases = sum(confirmed_cases, na.rm = TRUE))
covid_cases_state <- covid_cases_county %>% mutate(COUNTY = "State") %>% group_by(COUNTY, case_week) %>% summarize(confirmed_cases = sum(confirmed_cases, na.rm = TRUE))
covid_cases_all <- rbind(covid_cases_county, covid_cases_2S, covid_cases_state)
write.csv(covid_cases_all, "/Users/juliegil/Documents/git_synced_code/misapphire_private_moved/misapphire_private/data/state_covid_data_combined.csv", row.names = FALSE, na = "")
shiny::runApp('~/Documents/git_synced_code/misapphire_private_moved/misapphire_private')
runApp('~/Documents/git_synced_code/misapphire_private_moved/misapphire_private')
#patient_data <- read.csv("patient_details.csv") %>% arrange(desc(WEEK))
patient_data <- read.csv("/Users/juliegil/Documents/LauringLab_Code/code_for_misapphire_private_data_refresh/patient_details.csv") %>% arrange(desc(WEEK))
View(patient_data)
# landing page stats
one_set <- filter(patient_data, TYPE == "ByAge")
View(one_set)
total_samples <- sum(one_set$COUNT, na.rm = TRUE)
average_per_week <- one_set %>% group_by(WEEK) %>% summarize(total_per_week = sum(COUNT, na.rm = TRUE))
average_per_week <- mean(average_per_week$total_per_week)
average_per_week <- round(mean(average_per_week$total_per_week), 0)
mean(average_per_week$total_per_week)
average_per_week <- one_set %>% group_by(WEEK) %>% summarize(total_per_week = sum(COUNT, na.rm = TRUE))
average_per_week <- round(mean(average_per_week$total_per_week), 0)
start_point <- min(one_set$WEEK)
start_point <- filter(one_set, WEEK == min(one_set$WEEK))
View(start_point)
start_point <- paste0(month.abb[min(start_point$MONTH)], " ", substr(unique(start_point$WEEK), 1, 4))
end_point <- filter(one_set, WEEK == max(one_set$WEEK))
View(end_point)
end_point <- paste0(month.abb[max(start_point$MONTH)], " ", substr(unique(start_point$WEEK), 1, 4))
end_point <- paste0(month.abb[max(end_point$MONTH)], " ", substr(unique(end_point$WEEK), 1, 4))
runApp('~/Documents/git_synced_code/misapphire_private_moved/misapphire_private')
runApp('~/Documents/git_synced_code/misapphire_private_moved/misapphire_private')

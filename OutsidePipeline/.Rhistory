grepl("AY.", RESULT) ~ "Delta",
RESULT == "B.1.617.2" ~ "Delta",
RESULT == "B.1.1.7" ~ "Alpha",
grepl("Q.", RESULT) ~ "Alpha",
RESULT == "B.1.351" ~ "Beta",
RESULT == "P.1" ~ "Gamma",
RESULT == "B.1.427" ~ "Epsilon",
RESULT == "B.1.429" ~ "Epsilon",
RESULT == "B.1.525" ~ "Eta",
RESULT == "B.1.526" ~ "Iota",
RESULT == "B.1.617.1" ~ "Kappa",
RESULT == "B.1.621" ~ "Mu",
RESULT == "B.1.621.1" ~ "Mu",
RESULT == "P.2" ~ "Zeta",
grepl("B.", RESULT) ~ "Original B",
RESULT == "B" ~ "Original B",
RESULT == "D.2" ~ "Original B",
RESULT == "R.1" ~ "Original B",
RESULT == "C.37" ~ "Original B",
grepl("A.", RESULT) ~ "Original A",
RESULT == "A" ~ "Original A",
RESULT == "" ~ "No Call",
RESULT == "None" ~ "No Call",
RESULT == "Unassigned" ~ "No Call",
T ~ "Unknown"))
#colnames(patf_details2)
patf_details2 <- patf_details2 %>% select(PATIENT_MRN, PATIENT_SEX, PATIENT_ZIP, PATIENT_COUNTY, PATIENT_RACE, PATIENT_ETHNICITY, RESULT, COLL_MONTH, COLL_DATE, APPROX_AGE, collection_week, extra_clade)
#patf_details2 <- patf_details2 %>% mutate(PATIENT_MRN = paste0("10", PATIENT_MRN, "01"))
patf_details2 <- patf_details2 %>% mutate(PATIENT_RACE = case_when(PATIENT_RACE == "W" ~ "White or Caucasian",
PATIENT_RACE == "B" ~ "Black or African American",
PATIENT_RACE == "O" ~ "Other",
PATIENT_RACE == "U" ~ "Unknown",
PATIENT_RACE == "A" ~ "Asian",
PATIENT_RACE == "M" ~ "Multiple",
PATIENT_RACE == "I" ~ "American Indian and Alaska Native",
PATIENT_RACE == "D" ~ "Patient Refused",
PATIENT_RACE == "P" ~ "Native Hawaiian and Other Pacific Islander",
T ~ PATIENT_RACE))
patf_details2 <- patf_details2 %>% mutate(AGE_GROUP = case_when(APPROX_AGE < 18 ~ "Under 18",
APPROX_AGE >= 18 & APPROX_AGE < 30 ~ "18-29",
APPROX_AGE >= 30 & APPROX_AGE < 50 ~ "30-49",
APPROX_AGE >= 50 ~ "50+",
T ~ "Unknown"))
# set one
strain_by_sex <- patf_details2 %>% group_by(PATIENT_SEX, extra_clade, collection_week) %>% summarize(max_month = max(COLL_MONTH), count = length(unique(PATIENT_MRN)))
strain_by_sex$TYPE <- "BySex"
colnames(strain_by_sex) <- c("DEMO", "CLADETYPE", "WEEK", "MONTH", "COUNT", "TYPE")
# set two
strain_by_race <- patf_details2 %>% group_by(PATIENT_RACE, extra_clade, collection_week) %>% summarize(max_month = max(COLL_MONTH), count = length(unique(PATIENT_MRN)))
strain_by_race$TYPE <- "ByRace"
colnames(strain_by_race) <- c("DEMO", "CLADETYPE", "WEEK", "MONTH", "COUNT", "TYPE")
# set three
strain_by_eth <- patf_details2 %>% group_by(PATIENT_ETHNICITY, extra_clade, collection_week) %>% summarize(max_month = max(COLL_MONTH), count = length(unique(PATIENT_MRN)))
strain_by_eth$TYPE <- "ByEth"
colnames(strain_by_eth) <- c("DEMO", "CLADETYPE", "WEEK", "MONTH", "COUNT", "TYPE")
# set four
strain_by_age <- patf_details2 %>% group_by(AGE_GROUP, extra_clade, collection_week) %>% summarize(max_month = max(COLL_MONTH), count = length(unique(PATIENT_MRN)))
strain_by_age$TYPE <- "ByAge"
colnames(strain_by_age) <- c("DEMO", "CLADETYPE", "WEEK", "MONTH", "COUNT", "TYPE")
total_patient_details <- rbind(strain_by_age, strain_by_eth, strain_by_race, strain_by_sex)
#patf_details2$PATIENT_MRN <- lapply(patf_details2$PATIENT_MRN, function(x) {digest::digest(x, algo="md5", serialize = F)})
#total_patient_details <- total_patient_details %>% mutate(MONTH = month.abb[as.numeric(MONTH)])
total_patient_details <- total_patient_details %>% mutate(across(everything(), as.character))
write.csv(total_patient_details, "/Users/juliegil/Documents/LauringLab_Code/code_for_misapphire_private_data_refresh/patient_details.csv", row.names = FALSE, na = "")
write_sheet(data = total_patient_details, ss = patient_details_locale, sheet = "patient_details")
pd_zip <- patf_details2 %>% group_by(PATIENT_ZIP, extra_clade) %>% summarize(max_month = max(COLL_MONTH), count = length(unique(PATIENT_MRN)))
write.csv(pd_zip, "/Users/juliegil/Documents/LauringLab_Code/code_for_misapphire_private_data_refresh/zip_data.csv", row.names = FALSE, na = "")
write_sheet(data = pd_zip, ss = zip_data_locale, sheet = "zip_data")
pd_county <- patf_details2 %>% group_by(PATIENT_COUNTY, extra_clade, collection_week) %>% summarize(max_month = max(COLL_MONTH),
count = length(unique(PATIENT_MRN)),
#pieces = length(unique(RESULT)),
pieces2 = toString(unique(RESULT)))
write.csv(pd_county, "/Users/juliegil/Documents/LauringLab_Code/code_for_misapphire_private_data_refresh/county_data.csv", row.names = FALSE, na = "")
write_sheet(data = pd_county, ss = county_data_locale, sheet = "county_data")
# set where you'd like to download the file to:
output_filepath <- "/Users/juliegil/Documents/git_synced_code/misapphire_private_moved/misapphire_private/data/"
# set the file name of what you're downloading:
save_file_name <- "state_county_data.xlsx"
# read the html of the state website:
state_page <- read_html("https://www.michigan.gov/coronavirus/stats")
# get a list of all the html a nodes, where the urls are kept
state_a <- html_nodes(state_page, "a")
# find the a node that has the phrase we care about
phrase_of_interest <- "Onset of Symptoms"
for (i in seq(1,length(state_a))){
if (grepl(phrase_of_interest, as.character(state_a[[i]]))){
keep_url <- as.character(state_a[[i]])
}
}
# get the portion of the url from the a node that we care about, to make the data pull
i <- gsub("\\", "", as.character(keep_url), fixed = TRUE)
get_doc_url <- strsplit(i, ".xlsx")[[1]][1]
get_doc_url <- strsplit(get_doc_url, '.href=\"')[[1]][2]
doc_url <- substr(get_doc_url, 2, nchar(get_doc_url))
url <- paste0("https://www.michigan.gov/", doc_url, ".xlsx")
download.file(url, paste0(output_filepath, save_file_name), mode = "wb")
# read in the excel file you just created
excel_in <- read.xlsx(paste0(output_filepath, save_file_name), sheet = 1, detectDates = TRUE)
# write out the data into a csv instead
new_file_name_and_loc <- gsub(".xlsx", ".csv", paste0(output_filepath, save_file_name))
write.csv(excel_in, new_file_name_and_loc, row.names = FALSE, na = "")
# and delete the excel version
file.remove(paste0(output_filepath, save_file_name))
covid_cases_county <- read.csv(paste0(output_filepath, "state_county_data.csv")) # read in that data we just created
# create date and epi week columns
covid_cases_county <- filter(covid_cases_county, CASE_STATUS == "Confirmed") %>% mutate(Date = substr(Date, 1, 10),
week = epiweek(as_date(Date)))
# filter the data down to match available patient data range
covid_cases_county <- filter(covid_cases_county, as_date(Date) >= min(as_date(patf_details2$COLL_DATE)) & as_date(Date) <= max(as_date(patf_details2$COLL_DATE)))
covid_cases_county <- covid_cases_county %>% mutate(week = case_when(nchar(as.character(week)) == 1 ~ paste0("0", week),
T ~ as.character(week)),
case_week = case_when(week >= "52" & day(as_date(Date)) < 7 ~ paste0(year(as_date(Date)) - 1, "-", week),
T ~ paste0(year(as_date(Date)), "-", week)))
covid_cases_county2 <- covid_cases_county %>% mutate(COUNTY = case_when(COUNTY == "Detroit City" ~ "Wayne",
T ~ COUNTY))
covid_cases_county <- covid_cases_county %>% group_by(COUNTY, case_week) %>% summarize(confirmed_cases = sum(Cases, na.rm = TRUE))
covid_cases_2S <- filter(covid_cases_county, COUNTY %in% c("Wayne", "Washtenaw", "Detroit City", "Monroe")) %>% mutate(COUNTY = "Region 2S") %>% group_by(COUNTY, case_week) %>% summarize(confirmed_cases = sum(confirmed_cases, na.rm = TRUE))
covid_cases_state <- covid_cases_county %>% mutate(COUNTY = "State") %>% group_by(COUNTY, case_week) %>% summarize(confirmed_cases = sum(confirmed_cases, na.rm = TRUE))
covid_cases_all <- rbind(covid_cases_county, covid_cases_2S, covid_cases_state)
write.csv(covid_cases_all, "/Users/juliegil/Documents/git_synced_code/misapphire_private_moved/misapphire_private/data/state_covid_data_combined.csv", row.names = FALSE, na = "")
shiny::runApp('~/Documents/git_synced_code/misapphire_private_moved/misapphire_private')
runApp('~/Documents/git_synced_code/misapphire_private_moved/misapphire_private')
#patient_data <- read.csv("patient_details.csv") %>% arrange(desc(WEEK))
patient_data <- read.csv("/Users/juliegil/Documents/LauringLab_Code/code_for_misapphire_private_data_refresh/patient_details.csv") %>% arrange(desc(WEEK))
View(patient_data)
# landing page stats
one_set <- filter(patient_data, TYPE == "ByAge")
View(one_set)
total_samples <- sum(one_set$COUNT, na.rm = TRUE)
average_per_week <- one_set %>% group_by(WEEK) %>% summarize(total_per_week = sum(COUNT, na.rm = TRUE))
average_per_week <- mean(average_per_week$total_per_week)
average_per_week <- round(mean(average_per_week$total_per_week), 0)
mean(average_per_week$total_per_week)
average_per_week <- one_set %>% group_by(WEEK) %>% summarize(total_per_week = sum(COUNT, na.rm = TRUE))
average_per_week <- round(mean(average_per_week$total_per_week), 0)
start_point <- min(one_set$WEEK)
start_point <- filter(one_set, WEEK == min(one_set$WEEK))
View(start_point)
start_point <- paste0(month.abb[min(start_point$MONTH)], " ", substr(unique(start_point$WEEK), 1, 4))
end_point <- filter(one_set, WEEK == max(one_set$WEEK))
View(end_point)
end_point <- paste0(month.abb[max(start_point$MONTH)], " ", substr(unique(start_point$WEEK), 1, 4))
end_point <- paste0(month.abb[max(end_point$MONTH)], " ", substr(unique(end_point$WEEK), 1, 4))
runApp('~/Documents/git_synced_code/misapphire_private_moved/misapphire_private')
runApp('~/Documents/git_synced_code/misapphire_private_moved/misapphire_private')
library(tidyverse)
library(lubridate)
################################################################################
starting_path <- "C:/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
outputLOC <- paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/CDC_IVY_UPLOADS/")
seq_list <- read.csv(paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/full_compiled_data.csv"), colClasses = "character")
#seq_list_o <- read.csv(paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/full_compiled_data.csv"), colClasses = "character")
seq_list <- filter(seq_list, (received_source == "CDCIVY" | received_source == "CDCIVY4" | received_source == "CDCIVY5") & !grepl("Missing Date", flag))
## check for CDC IVY 4 samples (start with 22, ivy 3 == 21)
# if (any(substr(seq_list$subject_id, 1, 2) == 22)){
#   print("IVY 4 Samples Present, Need to separate for upload")
# }
if (length(unique(seq_list$sample_id)) != nrow(seq_list)){
stop("Duplicate sample IDs - handle accordingly")
}
## remove study withdraws
seq_list <- filter(seq_list, flag != "Withdrawn from study")
################################################################################
### fix date formatting
seq_list <- seq_list %>% mutate(coll_date = case_when(grepl("/", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%m/%d/%Y")),
grepl("-", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%Y-%m-%d")),
T ~ NA_character_))
# seq_list_o <- seq_list_o %>% mutate(coll_date = case_when(grepl("/", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%m/%d/%Y")),
#                                                       grepl("-", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%Y-%m-%d")),
#                                                       T ~ NA_character_))
################################################################################
# 6/18/2021 - no longer need this - will be doing full overwrite upload going forward
# After the first upload, we'll need to keep track of what has already been uploaded
# so we'll read in the full list, then read in the previous upload list, and only keep
# rows that are not in the previous upload list(s) to write out and upload the next time
# ivy_file_list <- list.files(pattern = "*.csv", path = paste0(outputLOC, "ARCHIVE/"))
#
# ivy_redcap <- data.frame()
# for (i in ivy_file_list){
#   one <- read.csv(paste0(outputLOC, "ARCHIVE/", i), colClasses = "character")
#   ivy_redcap <- rbind(ivy_redcap, one)
# }
#
# # select only rows from seqlist that are not in ivy_redcap
# combo <- anti_join(seq_list, ivy_redcap)
#length(unique(combo$sample_id))
#combo$flag <- ifelse(grepl("REDO", combo$SampleSourceLocation), "Re-run sample from batch #1", "")
################################################################################
colnames(seq_list) <- tolower(colnames(seq_list))
# add leading zero to month
if (nchar(month(Sys.Date())) == 1){
m <- paste0("0", month(Sys.Date()))
} else {
m <- month(Sys.Date())
}
# add leading zero to day
if (nchar(day(Sys.Date())) == 1){
d <- paste0("0", day(Sys.Date()))
} else {
d <- day(Sys.Date())
}
today <- paste0(year(Sys.Date()), m, d)
#ivy3 <- filter(seq_list, substr(subject_id, 1, 2) == 21)
ivy4 <- filter(seq_list, substr(subject_id, 1, 2) == 22)
ivy5 <- filter(seq_list, substr(subject_id, 1, 2) == 23)
# change subject_id to study_id
ivy4 <- ivy4 %>% select(sample_id, subject_id, coll_date,
flag, received_source, sitename, samplebarcode,
platedate, plateplatform, platenumber,
pangolin_lineage, pangolin_status, pangolin_note,
nextclade_clade, nextclade_totalmissing, nextclade_completeness,
gisaid_strain, gisaid_epi_isl, received_date, position, platename,
plateposition, samplesourcelocation, pangolearn_version,
pango_version, pangolin_version, nextclade_qcoverallscore, nextclade_qcoverallstatus,
nextclade_totalmutations, nextclade_totalnonacgtns)
names(ivy4)[names(ivy4) == 'subject_id'] <- 'study_id'
# change subject_id to study_id
ivy5 <- ivy5 %>% select(sample_id, subject_id, coll_date,
flag, received_source, sitename, samplebarcode,
platedate, plateplatform, platenumber,
pangolin_lineage, pangolin_status, pangolin_note,
nextclade_clade, nextclade_totalmissing, nextclade_completeness,
gisaid_strain, gisaid_epi_isl, received_date, position, platename,
plateposition, samplesourcelocation, pangolearn_version,
pango_version, pangolin_version, nextclade_qcoverallscore, nextclade_qcoverallstatus,
nextclade_totalmutations, nextclade_totalnonacgtns,
data_quality_rule, newest_pangolin_lineage, newest_pangolin_date)
#names(ivy5)[names(ivy5) == 'subject_id'] <- 'study_id'
#seq_list <- filter(seq_list, platenumber <= 49)
#write.csv(ivy3, paste0(outputLOC, "cdc_ivy3_", today, ".csv"), row.names = FALSE, na = "")
write.csv(ivy4, paste0(outputLOC, "cdc_ivy4_", today, ".csv"), row.names = FALSE, na = "")
write.csv(ivy5, paste0(outputLOC, "cdc_ivy5_", today, ".csv"), row.names = FALSE, na = "")
#table(seq_list$pangolin_lineage)
max(ivy5$coll_date)
max(ivy5$received_date)
library(tidyverse)
library(lubridate)
#### combining wwtp files for its share
library(tidyverse)
library(lubridate)
### read in files to combine
# file in location
fin_loc <- "C:/Users/juliegil/Dropbox (University of Michigan)/SPH-COVID Response/Jules/ITS_SHARE/"
# norovirus
noro <- read.csv(paste0(fin_loc, "norov_wastewater_data_all_cities.csv"))
# covid
cov <- read.csv(paste0(fin_loc, "covid_wastewater_data_all_cities.csv"))
# solids
sol <- read.csv(paste0(fin_loc, "solid_wastewater_data_all_cities.csv"))
table(sol$variable)
table(sol$organism)
sol <- sol %>% mutate(organism = case_when(organism == "Monkeypox" ~ "Mpox",
T ~ organism))
table(sol$organism)
sol <- read.csv(paste0(fin_loc, "solid_wastewater_data_all_cities.csv"))
# only giving rsv, influenza a, mpox
sol <- filter(sol, organism %in% c("Influenza A", "Monkeypox", "RSV"))
sol <- sol %>% mutate(organism = case_when(organism == "Monkeypox" ~ "Mpox",
T ~ organism))
head(sol)
head(cov)
colnames(cov)
colnames(sol)
# norovirus
noro <- read.csv(paste0(fin_loc, "norov_wastewater_data_all_cities.csv"))
noro <- noro %>% mutate(neg_limit = NA_character_)
# covid
cov <- read.csv(paste0(fin_loc, "covid_wastewater_data_all_cities.csv"))
cov <- cov %>% mutate(neg_limit = NA_character_)
colnames(noro)
colnames(cov)
noro <- read.csv(paste0(fin_loc, "norov_wastewater_data_all_cities.csv"))
noro <- noro %>% mutate(neg_limit = NA_character_,
type = "INFLUENT",
variable = NA_character_,
value = NVnormalizedPMMoV,
city = City,
seven_day_rolling_average = sevendayavg_nvpmmov,
fourteen_day_rolling_average = fourteendayavg_nvpmmov)
noro <- noro %>% select(Date, type, variable, value, city, seven_day_rolling_average,
fourteen_day_rolling_average, diff_7, subtract_7,
diff_14, subtract_14, seven_trend_direction, fourteen_trend_direction,
thirty_days_ago, organism, neg_limit)
# covid
cov <- read.csv(paste0(fin_loc, "covid_wastewater_data_all_cities.csv"))
cov <- cov %>% mutate(neg_limit = NA_character_)
noro_plus_cov <- rbind(noro, cov)
colnames(noro_plus_cov)
# solids
sol <- read.csv(paste0(fin_loc, "solid_wastewater_data_all_cities.csv"))
# only giving rsv, influenza a, mpox
sol <- filter(sol, organism %in% c("Influenza A", "Monkeypox", "RSV"))
sol <- sol %>% mutate(organism = case_when(organism == "Monkeypox" ~ "Mpox",
T ~ organism))
colnames(sol)
sol <- sol %>% select(Date, type, variable, value, city, seven_day_rolling_average,
fourteen_day_rolling_average, diff_7, subtract_7,
diff_14, subtract_14, seven_trend_direction,
fourteen_trend_direction, thirty_days_ago, organism, neg_limit)
cov_noro_sol <- rbind(noro_plus_cov, sol)
table(cov_noro_sol$type)
table(cov_noro_sol$neg_limit)
colnames(cov_noro_sol)
table(cov_noro_sol$city)
table(cov_noro_sol$organism)
table(cov_noro_sol$neg_limit)
# separate solids data processing for internal dashboard
source("C:/Users/juliegil/Dropbox (University of Michigan)/SPH-COVID Response/Jules/wigginton_datapipeline_development/development.R")
shell.exec("C:/Users/juliegil/Documents/UofM_Work/poseidon_app/git_refresh_code/update_git_code.bat")
library(tidyverse)
library(lubridate)
################################################################################
starting_path <- "/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/"
outputLOC <- paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/RVTN_UPLOADS/")
seq_list <- read.csv(paste0(starting_path, "SEQUENCING/SARSCOV2/4_SequenceSampleMetadata/FinalSummary/full_compiled_data.csv"), colClasses = "character")
################################################################################
seq_list <- seq_list %>% select(sample_id, subject_id, coll_date,
flag, received_source, SiteName, SampleBarcode,
PlateDate, PlatePlatform, PlateNumber,
pangolin_lineage, pangolin_probability, pangolin_status,
pangolin_note, nextclade_clade, nextclade_totalMissing,
nextclade_completeness, gisaid_strain, gisaid_epi_isl,
received_date, position,
PlateName, PlatePosition, SampleSourceLocation,
pangoLEARN_version, pango_version,
pangolin_version, pangolin_conflict,
nextclade_qcOverallScore, nextclade_qcOverallStatus, nextclade_totalMutations,
nextclade_totalNonACGTNs,
data_quality_rule, newest_pangolin_lineage, newest_pangolin_date, sample_id_lauring)
seq_list <- filter(seq_list, received_source == "RVTN" & !grepl("Missing Date", flag))
if (length(unique(seq_list$sample_id)) != nrow(seq_list)){
stop("Duplicate sample IDs - handle accordingly")
}
################################################################################
### fix date formatting
seq_list <- seq_list %>% mutate(coll_date = case_when(grepl("/", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%m/%d/%Y")),
grepl("-", coll_date) ~ as.character(as.POSIXct(coll_date, format = "%Y-%m-%d")),
T ~ NA_character_))
#colnames(seq_list) <- tolower(colnames(seq_list))
# add leading zero to month
if (nchar(month(Sys.Date())) == 1){
m <- paste0("0", month(Sys.Date()))
} else {
m <- month(Sys.Date())
}
# add leading zero to day
if (nchar(day(Sys.Date())) == 1){
d <- paste0("0", day(Sys.Date()))
} else {
d <- day(Sys.Date())
}
today <- paste0(year(Sys.Date()), m, d)
rvtn <- seq_list %>% select(sample_id, subject_id, coll_date,
flag, received_source, SiteName, SampleBarcode,
PlateDate, PlatePlatform, PlateNumber,
pangolin_lineage, pangolin_probability, pangolin_status,
pangolin_note, nextclade_clade, nextclade_totalMissing,
nextclade_completeness, gisaid_strain, gisaid_epi_isl,
received_date, position,
PlateName, PlatePosition, SampleSourceLocation,
pangoLEARN_version, pango_version,
pangolin_version, pangolin_conflict,
nextclade_qcOverallScore, nextclade_qcOverallStatus, nextclade_totalMutations,
nextclade_totalNonACGTNs,
data_quality_rule, newest_pangolin_lineage, newest_pangolin_date, sample_id_lauring)
colnames(rvtn) <- c("sample_id", "subject_id", "coll_date",
"flag", "received_source", "sitename", "samplebarcode",
"platedate", "plateplatform", "platenumber",
"pangolin_lineage", "pangolin_probability", "pangolin_status",
"pangolin_note", "nextclade_clade", "nextclade_totalmissing",
"nextclade_completeness", "gisaid_strain", "gisaid_epi_isl",
"received_date", "position",
"platename", "plateposition", "samplesourcelocation",
"pangolearn_version", "pango_version",
"pangolin_version", "pangolin_conflict",
"nextclade_qcoverallscore", "nextclade_qcoverallstatus", "nextclade_totalmutations",
"nextclade_totalnonacgtns",
"data_quality_rule", "newest_pangolin_lineage", "newest_pangolin_date", "public_gisaid")
#seq_list <- filter(seq_list, platenumber <= 49)
write.csv(rvtn, paste0(outputLOC, "rvtn_", today, ".csv"), row.names = FALSE, na = "")
#### Read in influenza full file
flu_file <- read.csv(paste0("/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/",
"SEQUENCING/INFLUENZA_A/4_SequenceSampleMetadata/FinalSummary/",
"full_compiled_data.csv"), colClasses = c("character"))
rv_flu <- filter(flu_file, grepl("RVTN", received_source) & !grepl("Missing Date", flag))
colnames(rv_flu)
#### segment ids in as blanks currently
# cdc_flu <- cdc_flu %>% mutate(PB2.Segment_ID = "",
#                               PB1.Segment_ID = "",
#                               PA.Segment_ID = "",
#                               NP.Segment_ID = "",
#                               NA.Segment_ID = "",
#                               MP.Segment_ID = "",
#                               NS.Segment_ID = "")
rv_flu <- rv_flu %>% select(sample_id, subject_id, coll_date, flag, received_source,
received_date, SampleBarcode, PlateName, nextclade_HA_clade,
nextclade_HA_qcOverallScore, nextclade_HA_qcOverallStatus,
nextclade_HA_totalMutations, nextclade_HA_totalNonACGTNs,
nextclade_HA_type, Isolate_Id, PB2.Segment_Id, PB1.Segment_Id, PA.Segment_Id, HA.Segment_Id,
NP.Segment_Id, NA.Segment_Id, MP.Segment_Id, NS.Segment_Id, Isolate_Name)
colnames(rv_flu) <- c("sample_id", "subject_id", "coll_date_flu", "flag_flu",
"received_source_flu", "received_date_flu", "sample_barcode_flu",
"plate_name_flu", "nextclade_ha_clade_flu", "nextclade_ha_qcoverallscore_flu",
"nextclade_ha_qcoverallstatus_flu", "nextclade_ha_totalmutations_flu",
"nextclade_ha_totalnonacgtns_flu", "nextclade_ha_type_flu", "isolate_id_flu", "pb2_segment_id_flu",
"pb1_segment_id_flu", "pa_segment_id_flu", "ha_segment_id_flu", "np_segment_id_flu",
"na_segment_id_flu", "mp_segment_id_flu", "ns_segment_id_flu", "isolate_name_flu")
today_date <- gsub("-", "", Sys.Date())
write.csv(rv_flu, paste0("/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/",
"SEQUENCING/INFLUENZA_A/4_SequenceSampleMetadata/FinalSummary/",
"RVTN_uploads/rvtn_flu_", today_date, ".csv"), row.names = FALSE, na = "")
View(rv_flu)
library(tidyverse)
library(lubridate)
library(openxlsx)
### flu format for CEIRR/iDPCC
place1 <- "/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/SEQUENCING/INFLUENZA_A/"
plate_run_use <- "20230112_IAV_Illumina_Run_40_SETD" ## UHS
flu_data <- read.csv(paste0(place1, "4_SequenceSampleMetadata/FinalSummary/full_compiled_data.csv"), colClasses = c("character"))
table(flu_data$PlateName)
library(tidyverse)
library(lubridate)
library(openxlsx)
### flu format for CEIRR/iDPCC
place1 <- "/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/SEQUENCING/INFLUENZA_A/"
plate_run_use <- "20230112_IAV_Illumina_Run_40_SETD" ## UHS
flu_data <- read.csv(paste0(place1, "4_SequenceSampleMetadata/FinalSummary/full_compiled_data.csv"), colClasses = c("character"))
flu_data <- filter(flu_data, PlateName == plate_run_use & received_source %in% c("UHS", "CBR"))
flu_data <- filter(flu_data, !grepl("Missing Date in Manifest", flag))
flu_data <- filter(flu_data, !grepl("Duplicate Sample", flag))
# remove controls
flu_data <- filter(flu_data, !grepl("_HeLa_", sample_id) & !grepl("_NC_", sample_id) & !grepl("_NC", sample_id))
# remove anything without nextclade designations
flu_data <- filter(flu_data, nextclade_HA_clade != "")
table(flu_data$received_source)
plate_run_use <- "20230112_IAV_Illumina_Run_40" ## UHS
place_out <- paste0(place1, "3_ProcessedGenomes/", plate_run_use, "/Segment_sequences/")
file_out <- "/Users/juliegil/Dropbox (University of Michigan)/MED-LauringLab/External_Projects_DataRequests/INFLUENZA/CEIRR_Format/to_submit/"
flu_data <- flu_data %>% mutate(Project_Identifier = case_when(received_source == "CBR" ~ "SP3-Lauring_7102",
received_source == "UHS" ~ "SP3-Lauring_7102",
T ~ "STOP"),
BioProject_Accession_Number = case_when(received_source == "CBR" ~ "PRJNA818282",
received_source == "UHS" ~ "PRJNA818282",
T ~ "STOP"))
if (any(flu_data$Project_Identifier == "STOP") | any(flu_data$BioProject_Accession_Number == "STOP")){
stop("Proper received source and identifier code(s) not aligned")
}
flu_data$Contributing_Institution <- "PEN214"
flu_data$Sample_Identifier <- flu_data$sample_id
flu_data$Embargo_End_Date <- "NA"
flu_data$Provisional_Authors <- "William Fitzsimmons, Emily Bendall, Julie Gilbert, Adam Lauring"
flu_data$Submission_Title <- "Human Influenza Virus Surveillance Michigan"
flu_data$Publication_PMID <- "NA"
flu_data$Molecule_Type <- "viral cRNA" #x
if (grepl("Nanopore", plate_run_use)){
# nanopore re-runs
flu_data$Sequencing_Technology <- "Oxford Nanopore" #x
} else {
# new & going forward
flu_data$Sequencing_Technology <- "Illumina"
}
flu_data$Forward_Primer <- "Uni12/Inf1: GGGGGGAGCAAAAGCAGG, Uni12/Inf3: GGGGGGAGCGAAAGCAGG" #x
flu_data$Reverse_Primer <- "Uni13/Inf1: CGGGTTATTAGTAGAAACAAGG" #x
if (grepl("Nanopore", plate_run_use)){
# nanopore re-runs
flu_data$Assembly_Method <- "samtools BWA"
flu_data$Assembler_Version <- "1.15.1 0.7.17"
} else {
# illumina new & going forward
flu_data$Assembly_Method <- "IRMA" #x
flu_data$Assembler_Version <- "v.0.6.1" #x
}
flu_data$Coverage <- "U" #x
flu_data$Genbank_Accession_Numbers <- "NA" #x
flu_data$Strain_Name <- paste0(flu_data$Isolate_Name, ifelse(flu_data$nextclade_HA_type == "H3" & flu_data$Isolate_Name != "", " (H3N2)",
ifelse(flu_data$nextclade_HA_type == "H1" & flu_data$Isolate_Name != "", " (H1N1)", ""))) #x
flu_data$Sample_Material <- "NPH" #x
flu_data$Surveillance_Sample <- "Y" #x
flu_data$Host_Species <- "Homo sapiens" #x
flu_data$Host_Common_Name <- "Human" #x
flu_data$Collection_Date <- format(as_date(flu_data$coll_date), "%d-%b-%Y") #x
flu_data$Collection_Country <- "USA" #x
flu_data$Lab_Host <- "Human" #x
flu_data$Parent_Strain_Name <- flu_data$Strain_Name #x
flu_data$Passage_History <- "ORI" #x
flu_data$Antigenic_Characterization <- "NA" #x
flu_data$Treatment <- "NA" #x
flu_data$Transmission_Method <- "NA" #x
flu_data$Severity <- "NA" #x
flu_data$Phenotype <- "NA" #x
flu_data$Comments <- "NA" #x
flu_data$File_Name <- paste0(flu_data$sample_id, ".fasta") #x
#flu_data$Organism <- NA_character_
#flu_data$Locus_Tag_Prefix <- NA_character_
# select all the necessary variables in correct order
output_flu <- flu_data %>% select(Project_Identifier, Contributing_Institution,
Sample_Identifier, BioProject_Accession_Number, Embargo_End_Date, Provisional_Authors,
Submission_Title, Publication_PMID, Molecule_Type, Sequencing_Technology, Forward_Primer,
Reverse_Primer, Assembly_Method, Assembler_Version, Coverage,
Genbank_Accession_Numbers, Strain_Name, Sample_Material, Surveillance_Sample,
Host_Species, Host_Common_Name, Collection_Date, Collection_Country,
Lab_Host, Parent_Strain_Name, Passage_History, Antigenic_Characterization,
Treatment, Transmission_Method, Severity, Phenotype,
Comments, File_Name)
output_flu <- filter(output_flu, Parent_Strain_Name != "")
write.csv(select(output_flu, Sample_Identifier), paste0(place_out, "ceirr_out.csv"), row.names = FALSE, na = "")
# add header
header_string <- "#DataTemplate:Submission for Sequence Metadata v2.3"
# write header to .csv file
write.table(header_string, file = paste0(file_out, "ceirr_lauring_", gsub("-", "", Sys.Date()),  ".csv"), row.names =FALSE, col.names = FALSE,sep = ",", append = TRUE)
# then write the rest of the data file
write.table(output_flu, file = paste0(file_out, "ceirr_lauring_", gsub("-", "", Sys.Date()),  ".csv"), row.names =FALSE, col.names = TRUE,sep = ",", append = TRUE)
